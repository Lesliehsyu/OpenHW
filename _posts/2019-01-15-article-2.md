---
layout: post
title:  "双目视觉重建系统设计"
author: XUP-2020
categories: [ project, 2020competition ]
image: assets/images/summer2020_2/cover.jpeg
---

![isolution]({{ site.baseurl }}/assets/images/all_white.jpg)

**双目视觉重建系统设计**

**by&nbsp;余全洲、张文愚&amp;王林丰**

**第一部分**

设计概述 /Design Introduction

（1.请概括地描述一下你的设计，可包括本设计目的、学习到的知识点、应用方向或者设想的应用场景等；2. 经组内成员讨论后以表格的形式描述项目中各成员在项目中发挥的作用或者贡献百分比；3.作品的展示照片）

**设计目的****：**

能够在FPGA上读入图片，并通过连接电脑或显示器显示两侧摄像头的左右图像，再内部及逆行并实时显示通过在FPGA上处理完成后的深度图像，深度图像采用深浅的灰度图并使用深度伪色彩图显示。

**具体项目内容：**

本项目的具体内容实在PYNQ-Z2上实现一个双目视觉的测距系统，能够通过传入的左右目图片，在PYNQ-Z2上实现透视仿射等变换，进行摄像头标定，进行矫正以及消除畸变，完成后继续使用立体匹配算法计算两个摄像头之间的视差，转为伪彩色的深度图，最后通过得到的视差图以及对应的映射矩阵进行三维重构，以此得到相应的深度图像。其中所应用的矩阵的乘法以及图片读取的方式均可以实现硬件加速，并且视情况进行量化。

**知识点：**

1、双目摄像头标定，打印棋盘板，首先对两个摄像头分别进行标定，消除由于改变空间坐标系以及镜头内部导致的刚体变形以及畸变。其通过对不同图片中棋盘格的角点的对应关系，来求出摄像头的内参变量（坐标系转换）以及外参变量（镜头导致的畸变），

![image_1]({{ site.baseurl }}/assets/images/summer2020_2/image_1.png)

以此来消除每一个摄像头内的更接近真实坐标系的棋盘图像。

之后在分别得到两个摄像头各自的参数后，需要对双目摄像头进行整体的标定，来消除由于两个摄像头之间拜访不平行或者微小旋转带来的误差，测量两个相机之间的相对位置。 为了计算目标点在左右两个视图上形成的视差首先要将该点在左右视图上两个对应点匹配起来，为了减少匹配搜索的范围，我们采用极线约束来对图片进行降维搜索，使得两幅图像的对极线恰好在同一水平线上，这样一幅图像上任意一点与其在另一幅图像上的对应点就必然具有相同的行号，只需在该行进行一维搜索即可匹配到对应点。最终实现左右视图的成像坐标原点一致，光轴平行，左右平面共面的效果。

&nbsp;

2、立体匹配：通过使用BM，SGBM等算法，通过SAD方法以及梯度方向等参数，来对两幅图像计算视差，使用灰度值来代表距离信息。

3、硬件加速，对于循环体优化，添加优化指令进行加速：通过unroll指令进行展开，并对端口进行展开；使用pipeline指令进行加速。可以对嵌套循环的不同循环层进行不同的优化指令，寻找最佳优化方式。

**设想应用场景：**

在工程中作为测距仪器使用。在工业层面，双目立体视觉还可以应用到某些工业零部件的三维信息测量、精细分拣等场景中，以及快速弧线焊接路线的设定。

&nbsp;

**作品展示**

首先需要现通过c++对相机参数进行运算校正后传入HLS工程，通过HLS工程进行双目校正操作，将校正完成的图片传入matlab进行对比，得到的结果如下：

![image_2]({{ site.baseurl }}/assets/images/summer2020_2/image_2.png) 

原始图像如下所示：

 ![image_3]({{ site.baseurl }}/assets/images/summer2020_2/image_3.png) 

最终得到的深度图如下所示：

![image_4]({{ site.baseurl }}/assets/images/summer2020_2/image_4.png) 

通过灰度图生成伪彩色图：

&nbsp;

![image_5]({{ site.baseurl }}/assets/images/summer2020_2/image_5.png) 

在得到深度图之后，通过将相机极坐标系转换为环境中直角坐标系获得点云，即得到图像中每个像素点的三维坐标信息，从而完成测距与重建功能。

&nbsp;

&nbsp;

&nbsp;

**第二部分**

系统组成及功能说明 /System Construction &amp; Function Description

（请对作品的1. 计划实现及已实现的功能；2. 项目系统框图；3. 使用的技术方向做说明）

1.已实现功能

通过C++程序进行双目摄像头标定，获得相机的内参矩阵、畸变系数、旋转矩阵等。

在**Pynq-z2**上实现了摄像头畸变校正、双目极线校正、立体匹配与生成深度图。

生成彩色深度图，并得到深度图中每一像素点的空间坐标。

2.技术方向说明

主要使用了双目视觉算法。双目视觉是模拟人类视觉原理，使用计算机被动感知距离的方法。从两个或者多个点观察一个物体，获取在不同视角下的图像，根据图像之间像素的匹配关系，通过三角测量原理计算出像素之间的偏移来获取物体的三维信息。

算法一般流程：

双目标定：获取相机的内参-焦距，图像中心，畸变系数等和外参-R（旋转）矩阵T（平移）矩阵，采用张正友的棋盘格标定方法。

双目校正：畸变校正+双目极线校正。相机成像的过程实际就是将世界坐标系的点，转换到相机坐标系，投影得到图像坐标系，进而转化为像素坐标系的过程。而由于透镜精度和工艺会引入畸变从而导致失真。采用**Bouguet** 极线校正算法，校正前的左右相机的光心并不是平行的，两个光心的连线就叫基线，像平面与基线的交点就是极点，像点与极点所在的直线就是极线，左右极线与基线构成的平面就是空间点对应的极平面；校正后，极点在无穷远处，两个相机的光轴平行，像点在左右图像上的高度达到一致。

立体匹配：由于前一步使用了极线约束进行了双目矫正，假定只有水平视差，于是可以使用BM算法实现立体匹配，采用半全局匹配算法，视差函数实现了基本块匹配和半全局块匹配算法。在&ldquo;块匹配&rdquo;方法中，该函数通过比较图像中每块像素的绝对差和(SAD)来计算视差，在&ldquo;半梯度&rdquo;匹配方法中，该函数还会将相似的视差强加到相邻的块上。这个附加的约束导致了一个比&ldquo;块匹配&rdquo;方法更完整的视差估计。

&nbsp;

&nbsp;

**第三部分**

完成情况及性能参数 /Final Design &amp; Performance Parameters

完成情况如下：

&nbsp;&nbsp;&nbsp; 预期实现在pynq-z2上实现双目相机标定、双目图像畸变矫正、双目极线校正、立体匹配及三维重建功能。在进行HLS设计时发现头文件&ldquo;hls_opencv&rdquo;没有办法被综合，由于相机标定中使用了大量opencv库函数，因此我们先使用visiual studio完成相机标定，获取相机参数，并将参数结果写入HLS头文件中。

&nbsp;&nbsp;&nbsp; 在进行图像矫正及立体匹配获取深度图像时，我们发现hls_video中存在图像校正函数hls::InitUndistortRectifyMap及基于BM算法的立体匹配函数hls::FindStereoCorrespondenceBM，由于函数已经封装完毕我们决定手动实现图像的校正及立体匹配，并对代码进行加速优化。最终实现了双目图像极线校正与立体匹配，并可以将图像转换为伪彩色图。

&nbsp;&nbsp;&nbsp; 在设计中，由于需要实现图像取像素点数值操作，最初我们定义了hls::Mat类型变量，然而发现，使用该类型变量无法从图像中提取每个确定坐标处像素点的值，在手动实现双目极线校正时处理一个像素需考虑其周围多个像素值，Mat类型无法满足我们的设计要求，最终在权衡板卡资源与速度之后选择定义二维数组来存放输入的左图像与右图像，在进行完双目极线校正后不将生成的新图像存储下来而直接送入立体匹配中，从而实现像素点级别流水线设计，节省了资源空间同时保持了地址访问的连续性。

&nbsp;&nbsp;&nbsp; 最终综合报告如下：

  

Vivado 设计如下：

&nbsp;

 ![image_6]({{ site.baseurl }}/assets/images/summer2020_2/image_6.png) 

Vivado 设计如下：

![image_7]({{ site.baseurl }}/assets/images/summer2020_2/image_7.png)

 

&nbsp;

&nbsp;

&nbsp;
