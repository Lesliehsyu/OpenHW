---
layout: post
title:  "手持医学影像智能分析仪"
author: XUP-2019
categories: [ project, 2019competition ]
image: assets/images/2019_1_14/cover.jpg
---

![isolution]({{ site.baseurl }}/assets/images/all_white.jpg)

**刘丽丽，阙禄颖，项晓强，张珍元，代光海**

**指导老师：周军**

**电子科技大学**

&nbsp;

**概述**

&nbsp;

**研究背景**

在疾病诊断中，医学影像学占有重要地位。医学影像数据以每年 30%的速度增长，占医院数字化数据的 90%[2]，放射科医师每天的图像数据浏览工作量剧增，且每年医疗资源和人力投入增长远远不能满足需求[3]，多重因素使放射科医师的工作超负荷。AI 技术可以利用高性能的图像识别和计算能力，在至少以下 3 个方面（皮肤病、眼病、肺病)将对当前临床放射诊断工作提供帮助

皮肤病方面，据统计，2017&nbsp;年近美国就有超过 87000 个新的黑色素瘤病例确诊，大约有 9300&nbsp;人以为此病死亡[4]。由于黑色素瘤和黑痣在外观上及其相似，所以依靠人眼直接判断较为困难。皮肤癌的诊断过程复杂又繁琐。许多患者因为工作繁忙、就医成本高等原因，很容易延误了就医时机。若仅需用手持设备拍摄一张清晰的皮肤表层图像，就可以对其进行预测，患者便可及时就医，通过专业的医疗手段进一步确诊病情，提高皮肤癌的防治效率；肺病方面，肺炎按照病理形态学划分，可以将肺炎分成大叶肺炎、间质肺炎、支气管肺炎及毛细支气管炎等[7]。不同的肺炎需要不同的治疗方案，然而目前肺炎类型判别主要依靠医生的个人经验，一些肺炎的 X&nbsp;光影像极为近似， 容易判别错误，造成误诊。将卷积神经网络用于肺炎 X&nbsp;光影影像分类，作为医生诊断肺炎类型的辅助工具，减少误诊的情况，给患者带来福音，具有重要的实用价值。眼病方面，&ldquo;视觉 2020&rdquo;全球防盲战略目标提出，约 50％的盲是可以治愈的(如白内障、沙眼等)， 约 30％的盲是可以预防的[5]，而可防可治性盲和低视力患者更多分布在经济欠发达的国家和地区，究其原因为医疗资源缺乏及分布不均衡等。人工智能眼病 OCT&nbsp;影像分析相对于传统的影像识别有更高的辨识率和可信度，相对于临床医生有更高的效率；

**研究意义**

手持仪器在医疗影像中也发挥了桥梁的作用。智能手持终端本身也具备处理功能，当出现明显信号或参数异常可以自动报警，特别是在灾区可以为挽救病人生命赢得了宝贵的时间。其次手持终端有利于疾病的早期诊断，也可缓解医院拥挤现像。

云端的设计让作品实现软件虚拟化，使用时动态传输数据，不使用时数据在系统中瞬间&ldquo;完全&rdquo;消失，[节省系统资源](https://baike.baidu.com/item/%E7%B3%BB%E7%BB%9F%E8%B5%84%E6%BA%90)；云端平台集成大量丰富数据集资源；将常用的数据清单备份至网络，对于没有信号的灾区有深刻的意义。

&nbsp;

本文设计以 Zynq&nbsp;Ualtra96 作为处理器搭建手持医学影像智能分析仪，能极大提高运算效率，具有操作简便、响应时间短、功耗低等优点。本作品既可通过手持仪器拍摄医学影像；又可作为一个云端，医学影像作为云端服务器的输入， 就三种疾病，即皮肤病 RGB 图像、眼病 OCT 图像和肺炎 X 光医学影像，采用深度学习算法对影像进行识别以及分析，最后将分析结果返回手持仪器的显示屏本系统。本作品主要的研究意义如下：

1、皮肤病可以对黑色素瘤、脂溢性角化病、黑痣三种类别进行识别和分析；

2、具有可扩展性，通过训练更多种类的数据集的，可以实现对其他病理的医学影像进行分析；

3、将深度学习算法移植到 Zynq 平台，提高运行速度、降低功耗；

4、可以辅助医学影像科室的医生进行分析，降低医生负担，减少误判率；

5、弥补偏远地区医疗水平有限的不足，大大提高乡村贫困地区医疗水平；

6、手持设备更加便捷，对疾病进行早期诊断，提醒患者及时就医；

7、云端可以集成更多数据资源，并可减轻终端的系统资源。

8、在完全没有信号的灾区，可通过 WiFi 模块组见局域网，手机可以连接到本产品并传送疫情图片，以便在危急时刻给出应急治疗方案。

&nbsp;

**主要创新点**

&nbsp;

**1.&nbsp;作品工程创新**

	1．医学与工学结合，实现&ldquo;机器诊断&rdquo;，大大节约了人力和物力。

	2．多种途径的疾病检测。具有实时拍照功能；也有 WiFi 模块在无信号时建局域网。

	3．硬件嵌入三种疾病的模型，功耗低，速度快，完成一对一的准确检测。

	4．可识别的医学影像包括可见光、OCT 和 X 光，具有很好的可拓展性。

	5．通过嵌入式 FPGA 平台将疾病识别模型进行集成和优化。

	6．手持的功能可在危急环境的灾区发挥救急的作用。

**2. 作品科学创新**


	本作品在现有可识别疾病的基础上，通过分析可得出患有其它病的风险。创新性地实现了 1+1&gt;2 的效果。实现了对患者的眼底图像进行端到端的糖尿病视网膜病变分类。具体如下：

	1、基于深度监督网络 ResNe 网络提出了一种新的网络架构进行分类。通过在 ResNet 网络的中间层引入深度监督的分类信号，不仅可以给网络训练提供额外的正则项，还可以使用引入深度监督层的预测结果进行多尺度的集成学习，从而提高网络的分类性能。

	2、引入多类别的代价敏感学习和一种剪切重采样的方法，克服了数据集极度不均衡带来的影响。

**系统架构**

**1. 方案论证与分析**

**1.1 网络模型的选择**

由于每种网络都有各自的优缺点，同时每种疾病的特征点也有很大的差别， 有的肉眼比较好判断，而有的却不好分辨，考虑到不浪费资源及适合的情形。可选用三种不同的网络来分别对三种疾病的分类进行训练，得到三种网络模型。对比多种主流的深度学习网络模型，最终对于这三种网络模型的选择如下：

1、眼病：由于 OCT 眼病数据集中图像特征比较明显，且形状比较单一，变化不大。用网络结果的主要思路是用密集成分来近似最优的局部稀疏结构，最终选择 MiniVGGNet；

2、肺病：肺结节良恶性识别的神经网络模型，通过对原始感兴趣区域划分局部子区域的方式增强训练样本，从网络深度、不同的激活函数及学习率衰减策略 3&nbsp;&nbsp;个方面对分类性能进行分析，选择最优参数组合，确定最终网络结构

GoogleNet。

3、皮肤病：我们选用的可见光下的皮肤病黑色素识别。由于是可见光下， 可想而知噪声的干扰会比较大，所以要选用可以识别到细微目标对象的特点的深层网络模型。针对黑色素瘤、黑色素痣和脂溢性角化病的三分类问题，所使用的方法包括残差神经网络、卷积特征提取过程、图像预处理和数据增强方法。最终选 Resnet-152。
	
**1.2&nbsp;开发平台的选择**

1、GPU：GPU 所具备的对大量数据可以进行并行运算以及拥有很高的主频和带宽等特点对神经网络模型进行加速起到了很好的效果。但是 GPU 的功耗过高且占用大量空间。FPGA 作为半定制芯片采用软硬件协同的设计方式，可以根据神经网络算法设计硬件结构，这给算法本身的优化提供了更大的空间。此外，

FPGA 能够完成流水线并行等 GPU 无法实现的功能。

2、Zynq Ultra96：Ultra96&trade;是 AVNET&nbsp;开发的，是基于 Xilinx&nbsp;Zynq UltraScale+

MPSOC 系列的芯片。为开发人员提供了一个独特而强大的开发环境，可简化机器学习。Ultra96 设计独特，可提供各种潜在外围设备，并具有可编程逻辑加速引擎，有助于降低开发流程的复杂性。该板包括四个用户可控 LED。设计工程师还可以添加外部配件（例如 Seeed Studio 平台上的 96Boards Grove&nbsp;入门套件中包含的配件），然后通过 96Boards 兼容的低速和高速扩展连接器与电路板进行交互。

对于日常生活中的应用来说，使用 GPU 局限性就很大，不仅不方便携带， 成本也是很高，且不可重复配置，功耗大。针对这一问题，采用基于 Zynq 平台来实现完成系统，在便携以及成本较低的情况下，硬件可编程，功耗相比 GPU 低上百倍， 提高效率。因此， 本图像分类系统所采用的 Zynq&nbsp;平台是基于ARM+FPAG 架构的，它可以更好地满足嵌入式机器视觉的应用以及发展，应用价值与市场前景都会更加广阔。

&nbsp;

**2. 系统原理分析**

**2.1 眼病的网络模型&mdash;&mdash;MiniVGGNet**

&nbsp;

VGG 的 CNN 构成主要有两部分： CONV 层仅使用 3&times;3 的核；应用 POOL 操作前堆叠多个 CONV=&gt;RELU 层（随着网络越深，连续的 CONV=&gt;RELU 数目通常减少）。

VGGNet 在应用单个 POOL 层之前将堆叠多个 CONV=&gt;RELU 层，允许网络在通过 POOL 层对输入空间尺寸做下采样之前可以从 CONV 层中学习到更丰富的特征。

MiniVGGNet 包含 CONV =&gt; RELU =&gt; CONV =&gt; RELU =&gt; POOL 两个集合，

之后跟着 FC&nbsp;=&gt; RELU&nbsp;=&gt; FC&nbsp;=&gt; SOFTMAX 层。前两个 CONV 层将学习 32 个 3

&times;3 的核，后两个 CONV 层将学习 64 个同样是 3&times;3 的核，POOL 层将执行 2&times;

2 核、stride 为 2&times;2 的 max pool 操作，在每个激活层之后跟着 BN 层并且在 POOL

和 FC 层之后跟上 Dropout 层。网络架构细节见表 2-1。

表&nbsp;2-1 MiniVGGNet&nbsp;层次表

![image_1]({{ site.baseurl }}/assets/images/2019_1_14/image_1.png)
	
**2.2 肺病的网络模型&mdash;&mdash;GoogleNet**

&nbsp;

1、GoogLeNet 采用了模块化的结构（Inception 结构），方便增添和修改；

2、网络最后采用了 average pooling（平均池化）来代替全连接层；

3、虽然移除了全连接，但网络依然使用了 Dropout；

4、为避免梯度消失，网络额外增加了 2 个辅助的 softmax 用于向前传导梯度（辅助分类器），将中间某一层的输出用作分类，按一个较小的权重加到最终分类结果中，相当于做了模型融合，同时给网络增加了反向传播的梯度信号，也提供了额外的正则化，对于整个网络的训练很有裨益。

GoogLeNet 的网络结构图细节如表 2-2 所示。

表 2-2 GoogLeNet 的网络结构信息表

![image_2]({{ site.baseurl }}/assets/images/2019_1_14/image_2.png)

**2.3&nbsp;皮肤病的网络模型&mdash;&mdash;ResNet-152**

&nbsp;

皮肤病整个框架的流程如图 2-1 所示。

![image_3]({{ site.baseurl }}/assets/images/2019_1_14/image_3.png)

(a)&nbsp;残差块&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;(b)深度特征提取&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;(c)支持向量机分类图

2-1&nbsp;黑色素瘤识别框架流程图

本系统采用了深度残差神经网络 ResNet-152，引入了残差连接，加速深度网络的收敛，通过大幅度提高网络深度来保持准确率的提高。深度残差网络由一组残差块组成，每个残差块包含几个堆叠的卷积层。具有恒等映射的残差块可以表示为：

&nbsp;

**<em style="font-style:italic">h**</em>**<em style="font-style:italic">l+1 &nbsp;**</em>**<em style="font-style:italic">=**</em>**<em style="font-style:italic">Relu(h**</em>**<em style="font-style:italic">l &nbsp;**</em>**<em style="font-style:italic">+**</em>**<em style="font-style:italic">F(h**</em>**<em style="font-style:italic">l **</em>**<em style="font-style:italic">,**</em>**<em style="font-style:italic">w**</em>**<em style="font-style:italic">l **</em>**<em style="font-style:italic">))&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;**</em>（2-1）

&nbsp;

式中，**<em style="font-style:italic">h**</em>**<em style="font-style:italic">l **</em>和 **<em style="font-style:italic">h**</em>**<em style="font-style:italic">l**</em>**<em style="font-style:italic">+**</em>**<em style="font-style:italic">1 **</em>分别是第 l 个残差块的输入和输出，Relu 是修正线性单元函数， **<em style="font-style:italic">F**</em>表示残差映射函数， **<em style="font-style:italic">w**</em>**<em style="font-style:italic">l **</em>是残差学习单元的参数。

本系统采用了 ResNet-152 模型，且残差网络在本系统的皮肤病数据集上进行了预训练。ResNet-152 结构详细信息如表 2-3 所示。

表 2-3 ResNet-152 网络结构信息表

![image_4]({{ site.baseurl }}/assets/images/2019_1_14/image_4.png)

![image_5]({{ site.baseurl }}/assets/images/2019_1_14/image_5.png)

**3. 系统硬件设计**

本文采用 UltraScale+MPSoC 架构的 ZYNQ 芯片作为处理器，将分类识别算法使用嵌入式软硬件协同工作的方式实现：将运算简单、具有较多判断语句和指针操作的算法模块交由 PS（Processing System）端软件实现；将对算法速度性能影响较大、可并行化程度高的部分用 PL（Programmable Logic）端的 FPGA 硬件加速器实现。

深度神经网络模型的权重参数往往存在大量冗余，在片上系统实现时会出现计算和存储资源上的瓶颈，同时也会产生大量的功耗。本文采用 DNNDK&trade;（Deep Neural Network Development Kit）对模型的数据位宽进行模型压缩优化，压缩后的模型由 Xilinx&reg;深度学习处理单元（DPU）来实现，DPU 的硬件架构如图 2-2 所示。DPU 是一种专用于卷积神经网络的可配置引擎，可以根据所选择的设备和应用来配置计算并行性。

![image_6]({{ site.baseurl }}/assets/images/2019_1_14/image_6.png)

图 2-2 DPU 硬件架构

在 DPU 硬件架构中，Xilinx&reg; FPGA 使用大量的片上存储来缓冲中间数据、输入和输出数据，并尽可能重复使用数据，以减少内存带宽，计算引擎采用深度流水线设计。

&nbsp;

图 2-3 &nbsp;是本系统的硬件连接示意图，DPU &nbsp;IP &nbsp;集成在 Zynq &nbsp;UltraScale&trade;+&nbsp;MPSoC 器件的可编程逻辑（PL）中，并通过 AXI&nbsp;Interconnect 连接到处理系统（PS）。每个 DPU 有一个从接口和三个主接口，其中一个主接口用于获取 DPU 指令，另外两个用于数据获取。DPU 通过 AXI Interconnect 连接到内存控制器来访问 DDR 内存。

![image_7]({{ site.baseurl }}/assets/images/2019_1_14/image_7.png)

图 2-3&nbsp;系统硬件连接示意图

&nbsp;

Ultra96&trade;是 AVNET 开发的，是基于 Xilinx Zynq UltraScale+ MPSOC 系列的芯片，具体使用的是：Xilinx Zynq UltraScale+ MPSoC ZU3EG SBVA484，其主要特点及开发板框架如图 2-4 所示。

![image_8]({{ site.baseurl }}/assets/images/2019_1_14/image_8.png)

图 2-4 Ultra96&trade;开发板框架

本设计的整体硬件连接图如图 2-5 所示。

![image_9]({{ site.baseurl }}/assets/images/2019_1_14/image_9.png)

图 2-5 整体硬件连接展示图

本设计外设有电源模块、液晶显示模块和、音频播放模块和摄像头模块。电源模块是采用两节可充电电池，可在不拆卸的条件下直接充电；液晶显示模块实现人机交互界面，操作简单，方便用户使用；音频播放模块由功放电路、MP3 电路和喇叭三部分组成，用来实现语音播放提示的功能；摄像头模块用来拍摄可见光图像。

**4. 软件设计与流程**

**4.1 软件设计**

&nbsp;

本系统将软件结构分为两部分：应用层和内核层，如图 2-6 所示。其中应用层可以分为用户应用程序和函数库；内核层分为 Linux 内核和 DPU 驱动，Linux 内核用于管理 Linux 系统中的硬件设备，供应用程序使用，DPU 驱动为软件程序调用 FPGA 深度学习加速器提供支持。

在应用程序中涉及到视频图像的读取、分类与识别及显示。如果采用单线程方式，先进行图像的读取，再进行对象的分类识别，最后再进行信息的显示，那么 CPU 的利用率相对较低，实时性将会受到影响。因此应用层中利用了多线程技术，图像的读取、检测与跟踪和显示分别开启不同的线程来处理。多线程技术是基于操作系统之上的，本文采用的操作系统为 Linux 系统。

![image_10]({{ site.baseurl }}/assets/images/2019_1_14/image_10.png)

图 2-6 软件结构框图

其中，内核层直接联系硬件和软件，使得应用软件通过 API 实现对硬件的操作，从而使硬件按照设计完成相应的工作。内核层中的 Linux Kernel 负责提供

Linux 系统所需的核心功能，主要包括为：进程管理、内存管理、文件系统、设备驱动。DPU Driver 在内核层中运行，其主要任务为任务的调度和高效的内存管理，避免 DPU 和 CPU 之间的内存复制开销。
	
**4.2 实现流程**

&nbsp;

1、数据集整理及预处理

本作品可识别三种疾病。眼病选用 OCT 影像，皮肤病选用可见光下黑色素皮肤病图像，肺病选用 X 光片。

对于深度学习大数据量的要求，上千张的图片数量也并不足够，因此，要对输入的图像进行一定变换，对图像进行数据增广，即进行随机裁剪、水平翻转、区域随机采样等操作来进行扩充，这可以使模型进行图像识别时更具有鲁棒性， 下面是数据增广规则：

（1）直接使用原始输入图像。

（2）对原始图像进行采样处理，采样出的片段占原始图像的 0.1、0.3、0.5、

0.7、0.9，以这个采样比例进行采样。

（3）随机对原始图像进行采样，得到采样片段。

采样得到的片段都为原始图像大小的[0.1,1] 之间，宽高比在[0.5, 2] 之间，若采集的片段与目标标定的矩形框有重叠的部分，则保留该部分，并对以上采样得到的片段尺寸转化为模型规定的大小，最后再对图像进行概率为 0.5 的水平翻转操作。

2、卷积神经网络的训练训练过程如下：

（1）训练前，建立网络并对网络进行权值初始化，根据设置网络的初始学习率，一般会使用随机梯度下降法，学习率会随着迭代次数的增加相应的减小， 如果这里没有设置合适的学习率，会出现震荡过拟合等现象。

（2）对模型所用训练集的图片进行均值计算，得到蓝绿红三个通道数的均值。

（3）对数据集进行预处理，把训练集和测试集分别转化为 Caffe 框架可读的

lmdb 格式的数据集，用作模型训练和测试的输入。

（4）开始训练模型，并加入了有监督的预训练，预训练是指使用一个已经用大量数据分类训练好的模型文件来初始化另一个网络模型，这个网络模型再根据新的输入进行微调，经过大量迭代次数后，这个网络模型便具备了在新的环境中的分类能力，在数据量不充足时能有效地训练复杂的卷积神经网络。使用了预训练模型，还可以有效地减少训练时间，提高效率。

（5）输入的图像数据通过卷积层、池化层和全连接层进行前向传播得到输出值，而后计算输出值与预期值之间的误差，即 loss 值。

（6）将得到的loss 值反向传播依次传递到低层，根据loss 值来调整网络的权值，来使下一次迭代训练的误差变小，直至满足预先设定的迭代次数。

（7）如果误差达到本文的期望值时，可以提前结束训练，得到模型文件以备用。

3、模型量化

深度学习运算量大、参数多，所以占用资源也较大，由于开发板的资源有限， 除了后续对其进行量化操作外，还要进行修改模型来减少它的输出量，符合可量化的要求，本文主要是对模型进行改进。

首先，DPU 仅支持 12 位来描述参数的数量，因此其不能超过212 -1 ，即 4095。要把参数数量超过此数的层的输出量减小。

其次，在量化过程中发现 DPU 不支持 Normalize 层，导致整个模型无法量化。用 batchnorm 层和 scale 层来代替 Normalize 层。

最后改进模型后继续在原有基础上训练即可。然后把得到的模型压缩，把浮点网络模型压缩为整型网络模型。再进行编译，把优化的 IR 映射到 DPU 指令流。



进行混合编译，主机链接器将主机代码和DPU 代码链接在一起，生成混合二进制可执行文件，其中包含了在 CPU 和 DPU 上异构运行所需的所有信息。

&nbsp;

**设计演示**

**1.&nbsp;系统测试**

**1.1 数据集样本**

&nbsp;

本文针对皮肤病中恶性黑色素瘤、良性黑色素痣、脂溢性角化病三种病进行识别，数据集样本图如图 3-1 所示。

![image_11]({{ site.baseurl }}/assets/images/2019_1_14/image_11.png)

(a)恶性黑色素瘤数据集样本图

![image_12]({{ site.baseurl }}/assets/images/2019_1_14/image_12.png)

(b)良性黑色素痣数据集样本图

![image_13]({{ site.baseurl }}/assets/images/2019_1_14/image_13.png)

(c)脂溢性角化病数据集样本图

图 3-1 三种皮肤病可见光数据集样本图

针对眼病中 CNV、DME、DRUSEN、NORMAL 四种 OCT 影像进行识别， 数据集样本图如图 3-2 所示。

![image_14]({{ site.baseurl }}/assets/images/2019_1_14/image_14.png)

1. （a）CNV&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;(b)DME&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; (c)DRUSEN&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; (d)NORMAL
	
图 3-2 四种眼病 OCT 数据集样本图

针对肺病对正常、细菌性肺炎、病毒性肺炎三种 X 光影响影响进行识别，数据集样本图如图 3-3 所示。

![image_15]({{ site.baseurl }}/assets/images/2019_1_14/image_15.png)

(a)正常 (b)细菌性肺炎 (c)病毒性肺炎

图&nbsp;3-3 三种肺病&nbsp;X&nbsp;光数据集样本图

分别对仪器上运行系统的准确性和实时性进行测试。以眼病为例，测试的结果如下。

**1.2 测试结果**

1、准确性测试

对模型性能的测试，查看模型的通用能力。

（1）皮肤病，输入图片为脂溢性角化病 keratosis。

![image_16]({{ site.baseurl }}/assets/images/2019_1_14/image_16.png)

（2）眼病，输入图片为 DME。

![image_17]({{ site.baseurl }}/assets/images/2019_1_14/image_17.png)

（3）肺病，输入图片为病毒性肺炎。

![image_18]({{ site.baseurl }}/assets/images/2019_1_14/image_18.png)

由上图，我们可以看到对于随意的一张图片，可以是图片得到正确分类的概率为 90%以上，远高于其他的分类的可能性，模型的判定准确率很好，达到了实验的要求。

2、实时性测试

测试系统实时性，最后经过测试，得到通过硬件调用 DPU 结构运行卷积神经网络，在硬件调用单线程进行目标检测所需要的时间为平均 193071us，即 1s 钟可以测试 5 张图片。人们等待结果的时间只需要 0.2s。

&nbsp;

**2.&nbsp;评价指标**

1、混淆矩阵

![insert_1]({{ site.baseurl }}/assets/images/2019_1_14/insert_1.png)

2、准确率（Precision）：表示预测为正例的样本中，真正的正例所占的比例， 可反映算法的查准性能，见式（3-1）。 

**<em style="font-style:italic">Precision**</em>=**<em style="font-style:italic">TP TP**</em>+&nbsp;**<em style="font-style:italic">FP**</em>&acute;100% &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;（3-1）

&nbsp;

3、召回率（Recall）：表示预测为正例的真实正例中，真实的正例占全部真实正例的比例，可反映算法的查全性能，见式（3-2）。 

**<em style="font-style:italic">Recall**</em>=**<em style="font-style:italic">TP TP**</em>+&nbsp;**<em style="font-style:italic">FN**</em>&acute;100% &nbsp; &nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;&nbsp;（3-2）

&nbsp;

**3. 误差分析**

首先对每种疾病进行测试，分别采用每种疾病的每个类别 200 张图片组成测试集。得到的结果进行整理，得到各项指标如下所示。

**3.1 OCT&nbsp;眼病**

&nbsp;

（1）混淆矩阵

![insert_2]({{ site.baseurl }}/assets/images/2019_1_14/insert_2.png)

（2）准确率

CNV&nbsp;: 200/200=100% DME: 197/200=98.5% DRUSEN: 178/200=89% NORMAL: 194/200=97%

（3）召回率

CNV: 200/(200+3+43)=81.3% DME: 197/198=99.4%



DRUSEN: 178/（178+5）=97.2% NORMAL: 200/200=100%

	1. &nbsp;

**3.2 皮肤病**

（1）混淆矩阵

![insert_3]({{ site.baseurl }}/assets/images/2019_1_14/insert_3.png)

（2）准确率

良性黑痣: 167/200=83.5%

脂溢性角化病: 179/200=89.5%

恶性黑色素瘤: 171/200=85.5%

（3）召回率

良性黑痣: 167/(167+4+10)=92.23%

脂溢性角化病: 179/(5+179+21)=87.3%

恶性黑色素瘤: 171/(29+17+171)=78.8%

**3.3 肺部 X&nbsp;光**

（1）混淆矩阵

![insert_4]({{ site.baseurl }}/assets/images/2019_1_14/insert_4.png)

（2）准确率

正常: 179/200=89.5%

病毒性肺炎: 182/200=91%

细菌性肺炎: 190/200=95%

（3）召回率

正常: 179/(179+9+6)=92.27%



病毒性肺炎: 182/(182+11+4)=92.39%

细菌性肺炎: 190/(190+10+9)=90.91%

从混淆矩阵上来看，对角线代表正确识别的数量，颜色的深浅代表图片数量的多少。可以看到每种疾病对角线基本都为深色，效果良好。

从准确率和召回率来看，每种疾病准确率都能达到 85%以上，召回率都能达到 80%以上。
