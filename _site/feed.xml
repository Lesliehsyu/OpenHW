<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.0">Jekyll</generator><link href="/OpenHW/feed.xml" rel="self" type="application/atom+xml" /><link href="/OpenHW/" rel="alternate" type="text/html" /><updated>2021-03-26T13:50:46+08:00</updated><id>/OpenHW/feed.xml</id><title type="html">OpenHW</title><subtitle>OpenHW is a website that accomodate various opensource projects</subtitle><entry><title type="html">News wait to be released</title><link href="/OpenHW/welcome-to-jekyll/" rel="alternate" type="text/html" title="News wait to be released" /><published>2019-02-04T00:00:00+08:00</published><updated>2019-02-04T00:00:00+08:00</updated><id>/OpenHW/welcome-to-jekyll</id><content type="html" xml:base="/OpenHW/welcome-to-jekyll/">&lt;p&gt;You’ll find this post in your &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_posts&lt;/code&gt; directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;jekyll serve&lt;/code&gt;, which launches a web server and auto-regenerates your site when a file is updated.&lt;/p&gt;

&lt;p&gt;To add new posts, simply add a file in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_posts&lt;/code&gt; directory that follows the convention &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;YYYY-MM-DD-name-of-post.ext&lt;/code&gt; and includes the necessary front matter. Take a look at the source for this post to get an idea about how it works.&lt;/p&gt;

&lt;p&gt;Jekyll also offers powerful support for code snippets:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;print_hi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;nb&quot;&gt;puts&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Hi, &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;#{&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;print_hi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'Tom'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#=&amp;gt; prints 'Hi, Tom' to STDOUT.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Check out the &lt;a href=&quot;https://jekyllrb.com/docs/home&quot;&gt;Jekyll docs&lt;/a&gt; for more info on how to get the most out of Jekyll. File all bugs/feature requests at &lt;a href=&quot;https://github.com/jekyll/jekyll&quot;&gt;Jekyll’s GitHub repo&lt;/a&gt;. If you have questions, you can ask them on &lt;a href=&quot;https://talk.jekyllrb.com/&quot;&gt;Jekyll Talk&lt;/a&gt;.&lt;/p&gt;</content><author><name>XUP-2020</name></author><category term="news" /><summary type="html">You’ll find this post in your _posts directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run jekyll serve, which launches a web server and auto-regenerates your site when a file is updated.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="/OpenHW/assets/images/demo1.jpg" /><media:content medium="image" url="/OpenHW/assets/images/demo1.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">全国大学生集成电路创新创业大赛</title><link href="/OpenHW/univ-ciciec/" rel="alternate" type="text/html" title="全国大学生集成电路创新创业大赛" /><published>2019-02-03T00:00:00+08:00</published><updated>2019-02-03T00:00:00+08:00</updated><id>/OpenHW/univ-ciciec</id><content type="html" xml:base="/OpenHW/univ-ciciec/">&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/ciciec_2.jpg&quot; alt=&quot;rank&quot; /&gt;&lt;/p&gt;

&lt;p&gt;全国大学生集成电路创新创业大赛”以服务产业发展需求为导向，以提升我国集成电路产业人才培养质量为目标，打造产学研用协同创新平台，将行业发展需求融入教学过程，提升在校大学生创新实践能力、工程素质以及团队协作精神，助力我国集成电路产业健康快速发展。&lt;/p&gt;

&lt;h2 id=&quot;赛事时间&quot;&gt;赛事时间&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/ciciec_2.png&quot; alt=&quot;rank&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;报名地址&quot;&gt;报名地址&lt;/h2&gt;

&lt;p&gt;大赛官网：http://univ.ciciec.com&lt;/p&gt;

&lt;p&gt;其中，同学们在各个杯赛参赛的考量之中使用Xilinx的板卡平台上做对应的项目，我们在这里也开放对应板卡的平台借用。&lt;/p&gt;

&lt;h2 id=&quot;参赛项目排名&quot;&gt;参赛项目排名&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/ciciec_3.png&quot; alt=&quot;rank&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;关于平台借用&quot;&gt;关于平台借用&lt;/h2&gt;

&lt;p&gt;Xilinx学术合作公众号，点击联系 -&amp;gt; 平台试用。&lt;/p&gt;</content><author><name>XUP-2020</name></author><category term="competition" /><category term="news" /><category term="competition" /><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="/OpenHW/assets/images/ciciec_2.jpg" /><media:content medium="image" url="/OpenHW/assets/images/ciciec_2.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">2019创创黑客松(人工智能 × 物联网 创新创业竞赛)</title><link href="/OpenHW/hackson/" rel="alternate" type="text/html" title="2019创创黑客松(人工智能 × 物联网 创新创业竞赛)" /><published>2019-02-02T00:00:00+08:00</published><updated>2019-02-02T00:00:00+08:00</updated><id>/OpenHW/hackson</id><content type="html" xml:base="/OpenHW/hackson/">&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/hackson_2.png&quot; alt=&quot;rank&quot; /&gt;
&lt;img src=&quot;/OpenHW/assets/images/hackson_3.png&quot; alt=&quot;rank&quot; /&gt;
&lt;img src=&quot;/OpenHW/assets/images/hackson_4.png&quot; alt=&quot;rank&quot; /&gt;
&lt;img src=&quot;/OpenHW/assets/images/hackson_5.png&quot; alt=&quot;rank&quot; /&gt;&lt;/p&gt;
&lt;h1 id=&quot;大赛官网&quot;&gt;大赛官网&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;http://www.istunet.com/WebPage/istunet_web/hackathon_method_iot.html&quot;&gt;http://www.istunet.com/WebPage/istunet_web/hackathon_method_iot.html&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;参赛项目排名&quot;&gt;参赛项目排名&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/hackson_6.png&quot; alt=&quot;rank&quot; /&gt;&lt;/p&gt;</content><author><name>XUP-2020</name></author><category term="competition" /><category term="news" /><category term="competition" /><summary type="html">大赛官网</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="/OpenHW/assets/images/hackson_1.png" /><media:content medium="image" url="/OpenHW/assets/images/hackson_1.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">中国研究生电子设计竞赛</title><link href="/OpenHW/cpipc-introduction/" rel="alternate" type="text/html" title="中国研究生电子设计竞赛" /><published>2019-02-01T00:00:00+08:00</published><updated>2019-02-01T00:00:00+08:00</updated><id>/OpenHW/cpipc-introduction</id><content type="html" xml:base="/OpenHW/cpipc-introduction/">&lt;p&gt;中国研究生电子设计竞赛每两年举办一次，自2014年第九届竞赛开始，改为一年举办一次。自1996年首届竞赛由清华大学发起并举办以来，始终坚持“激励创新、鼓励创业、提高素质、强化实践”的宗旨，经过二十余年的发展，竞赛覆盖了全国大部分电子信息类研究生培养高校及科研院所，并吸引了港澳台地区和亚太地区的代表队参赛。&lt;/p&gt;

&lt;h2 id=&quot;其中特别设立了xilinx企业专项奖&quot;&gt;其中特别设立了Xilinx企业专项奖&lt;/h2&gt;

&lt;h3 id=&quot;一奖项设置&quot;&gt;一、奖项设置&lt;/h3&gt;

&lt;p&gt;一等奖    1名  10000元奖金 + PYNQ-Z2开发板&lt;/p&gt;

&lt;p&gt;二等奖    4名  PYNQ-Z2开发板&lt;/p&gt;

&lt;h3 id=&quot;二评选对象&quot;&gt;二、评选对象&lt;/h3&gt;

&lt;p&gt;2019第十四届研电赛中，所有基于赛灵思平台的参赛作品均可报名参加赛灵思企业专项奖评选。&lt;/p&gt;

&lt;h3 id=&quot;三技术要求&quot;&gt;三、技术要求&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;提供作品介绍文档（中文 + 英文）,包含：&lt;/p&gt;

    &lt;p&gt;a.  作品简介&lt;/p&gt;

    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;500字左右的作品介绍，请描述作品来源、功能、架构、创新点/难点、外设清单等。
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;b.  系统框图&lt;/p&gt;

    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;清楚展示系统的结构、外设连接、硬件资源分配等信息。
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;c.  作品展示照片（1-5张）&lt;/p&gt;

    &lt;p&gt;d.  Github源代码链接（鼓励开源，非强制）&lt;/p&gt;

    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;模板链接: https://pan.baidu.com/s/10IYRALocHeO-jRZ88hCJmg

提取码: 45vx          
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;提供3分钟左右的作品视频文件(或链接)，内容以作品演示为主。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;四评审标准&quot;&gt;四、评审标准&lt;/h3&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;创新性/实用性&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;难度/工作量&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;平台结合度&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;作品完成度&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;30%&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;30%&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;20%&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;20%&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;参赛项目排名&quot;&gt;参赛项目排名&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/cpipc_rank.png&quot; alt=&quot;rank&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;大赛官网&quot;&gt;大赛官网&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://cpipc.chinadegrees.cn/cw/hp/6&quot;&gt;https://cpipc.chinadegrees.cn/cw/hp/6&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;关于平台借用&quot;&gt;关于平台借用&lt;/h2&gt;
&lt;p&gt;Xilinx学术合作公众号，点击联系 -&amp;gt; 平台试用。&lt;/p&gt;</content><author><name>XUP-2020</name></author><category term="competition" /><category term="news" /><category term="competition" /><summary type="html">中国研究生电子设计竞赛每两年举办一次，自2014年第九届竞赛开始，改为一年举办一次。自1996年首届竞赛由清华大学发起并举办以来，始终坚持“激励创新、鼓励创业、提高素质、强化实践”的宗旨，经过二十余年的发展，竞赛覆盖了全国大部分电子信息类研究生培养高校及科研院所，并吸引了港澳台地区和亚太地区的代表队参赛。</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="/OpenHW/assets/images/cpipc.jpg" /><media:content medium="image" url="/OpenHW/assets/images/cpipc.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">基于SEA的飞机大战游戏</title><link href="/OpenHW/airforced-game-based-on-SEA/" rel="alternate" type="text/html" title="基于SEA的飞机大战游戏" /><published>2019-01-30T00:00:00+08:00</published><updated>2019-01-30T00:00:00+08:00</updated><id>/OpenHW/airforced-game-based-on-SEA</id><content type="html" xml:base="/OpenHW/airforced-game-based-on-SEA/">&lt;p&gt;作者：卞思格；宋长骏；陈炜鑫&lt;/p&gt;

&lt;p&gt;第一部分 设计概述&lt;/p&gt;

&lt;p&gt;1.1 设计目的&lt;/p&gt;

&lt;p&gt;我们设计了一款基于 SEA 的飞机大战游戏。飞机大战游戏是一款休闲益 智类游戏，既简单又耐玩。在初始界面，我们有开始游戏、重新开始、皮肤 选择和结束游戏四个选项。开始游戏后，玩家可以用游戏手柄方便的控制飞 机在屏幕上向任意方向移动，通过躲避子弹和射击敌机得分，在屏幕左上角 可以看到当前生命和得分。&lt;/p&gt;

&lt;p&gt;1.2 应用领域&lt;/p&gt;

&lt;p&gt;最近的一些复古游戏网上商店吸引了许多喜欢老式电子游戏的买家。一 些爱好者一直在收集复古游戏产品，一些普通玩家也开始收集旧式磁带和 CD，还有小时候玩过的游戏机。&lt;/p&gt;

&lt;p&gt;虽然复古游戏只占全球 1090 亿美金游戏行业的一小部分，但确是非常 有吸引力的缝隙市场。该游戏平台可以作为一个复古游戏机使用，经过后期 加工改良，可以将游戏移植到专用游戏机或手机等设备上，供玩家使用。这 款飞机大战游戏，可以放松心情，释放压力，提高反应能力。&lt;/p&gt;

&lt;p&gt;1.3 主要技术特点&lt;/p&gt;

&lt;p&gt;（1） 在 BRAM 资源较少的情况下，采用了图片压缩编码的方式，以较少 的数据量来表示原来的像素矩阵。&lt;/p&gt;

&lt;p&gt;（2） 我们编写了游戏的主菜单和控制逻辑，游戏功能丰富，界面美观。&lt;/p&gt;

&lt;p&gt;（3） 我们外接了自制游戏手柄，可以直插在开发板上，方便地控制游戏。&lt;/p&gt;

&lt;p&gt;1.4 关键性能指标&lt;/p&gt;

&lt;p&gt;（1） 游戏界面美观，飞机图标清晰，游戏动画显示流畅；&lt;/p&gt;

&lt;p&gt;（2） 游戏手柄上的摇杆与按键灵敏度高、指令延迟小&lt;/p&gt;

&lt;p&gt;1.5 主要创新点&lt;/p&gt;

&lt;p&gt;（1） 使用了自制游戏手柄，相比普通按键，能更方便地控制游戏，提升用 户体验。&lt;/p&gt;

&lt;p&gt;（2） 在板载 BRAM，资源较少的情况下，采用了图片压缩编码的方式，以 较少的数据量来表示原来的像素矩阵。&lt;/p&gt;

&lt;p&gt;第二部分 系统组成及功能说明&lt;/p&gt;

&lt;p&gt;2.1 整体介绍&lt;/p&gt;

&lt;p&gt;系统硬件由 SEA 开发板（型号 xc7s25ftgb196-1）、游戏手柄拓展板和 HDMI 显示屏组成。FPGA 读取按键和摇杆的状态，来控制游戏显示的内容， 其中，FPGA 通过 IIC 方式来读取摇杆的状态。游戏总体控制模块分为按键 功能控制、主菜单控制、游戏逻辑控制和文字图片信息显示控制四个方面。 根据玩家不同的指令，HDMI 屏上显示相应的内容。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/airforce_game_1.png&quot; alt=&quot;system_diagram&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/airforce_game_2.png&quot; alt=&quot;RTL_invivado&quot; /&gt;&lt;/p&gt;

&lt;p&gt;2.2 各模块介绍&lt;/p&gt;

&lt;p&gt;根据总体系统框图，给出各模块的具体设计说明。&lt;/p&gt;

&lt;p&gt;（1） 游戏总体控制模块&lt;/p&gt;

&lt;p&gt;按键功能控制：不同的按键对应不同的指令，该模块主要负责按键消 抖与指令转化。&lt;/p&gt;

&lt;p&gt;主菜单控制：游戏初始界面的主菜单有开始游戏、重新开始、皮肤选 择和结束游戏四个选项。可以通过按键上下移动光标，选择不同功能。&lt;/p&gt;

&lt;p&gt;游戏逻辑控制：该模块主要进行了游戏规则的设计。&lt;/p&gt;

&lt;p&gt;显示模块：主要负责文字显示和飞机图标、子弹显示。&lt;/p&gt;

&lt;p&gt;（2） HDMI 显示驱动模块：驱动 HDMI 屏，在屏上流畅的显示游戏界面。&lt;/p&gt;

&lt;p&gt;（3） 游戏手柄驱动模块：驱动手柄上的 PCF8591 芯片，输出摇杆的位置状 态。&lt;/p&gt;

&lt;p&gt;（4） IIC 通信模块：实现游戏手柄和 FPGA 的通信，FPGA 读取 PCF8591 输出的数据。&lt;/p&gt;

&lt;p&gt;第三部分 完成情况及性能参数&lt;/p&gt;

&lt;p&gt;显示的菜单如图 3 所示，可以上下移动光标选择相应的功能。游戏界面如图 4 所示，实现了摇杆控制飞机朝任意方面移动。图片清晰，画面显示流畅，指令 延时小，并且游戏规则正确，可以给玩家良好的游戏体验感。完整作品如&lt;/p&gt;

&lt;p&gt;第四部分 总结&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/airforce_game_3.png&quot; alt=&quot;game_introduction&quot; /&gt;
&lt;img src=&quot;/OpenHW/assets/images/airforce_game_4.png&quot; alt=&quot;game_introduction&quot; /&gt;
&lt;img src=&quot;/OpenHW/assets/images/airforce_game_5.png&quot; alt=&quot;game_introduction&quot; /&gt;&lt;/p&gt;

&lt;p&gt;4.1 可扩展之处&lt;/p&gt;

&lt;p&gt;A.利用板载的 esp32 模块，实现脱机下载。&lt;/p&gt;

&lt;p&gt;B.可以存储一些其他游戏，设计个游戏选择菜单。&lt;/p&gt;

&lt;p&gt;C.利用板载的蓝牙模块，实现联机游戏。&lt;/p&gt;

&lt;p&gt;D.增加游戏音乐部分&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;It would seem the claim could also extend to die cut books in general, as we can’t find anything sooner, but do let us know in the comments if you have further light to shed on this! Such books are, of course, still popular in children’s publishing today, though the die cutting is not now limited to mere outlines, as evidenced in a beautiful 2014 version of the same Little Red Riding Hood story.&lt;/p&gt;
&lt;/blockquote&gt;</content><author><name>XUP-2020</name></author><category term="project" /><category term="2020competition" /><summary type="html">作者：卞思格；宋长骏；陈炜鑫</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="/OpenHW/assets/images/airforce_game_cover.jpg" /><media:content medium="image" url="/OpenHW/assets/images/airforce_game_cover.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">基于 FPGA 和麦克风阵列的高速高精度声源定位</title><link href="/OpenHW/sound-source-detected-based-on-fpga-and-microphone-arrays/" rel="alternate" type="text/html" title="基于 FPGA 和麦克风阵列的高速高精度声源定位" /><published>2019-01-29T00:00:00+08:00</published><updated>2019-01-29T00:00:00+08:00</updated><id>/OpenHW/sound-source-detected-based-on-fpga-and-microphone-arrays</id><content type="html" xml:base="/OpenHW/sound-source-detected-based-on-fpga-and-microphone-arrays/">&lt;p&gt;作者：赵辰宇、白瑞昕、张慈庭&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/all_white.jpg&quot; alt=&quot;isolution&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;第一部分-设计概述--design-introduction&quot;&gt;第一部分 设计概述 / Design Introduction&lt;/h2&gt;
&lt;p&gt;1.1 设计目的&lt;/p&gt;

&lt;p&gt;频繁杂乱的鸣笛声，不但给周边居民的生活质量造成很大影响，而且增加了驾驶员的疲劳，影响行驶安全，并使乘客和行人在出行时倍感烦躁不安。在大多 数城市的道路上，时常出现禁止鸣笛的标志，然而并不是所有人都能自觉地遵守 规则，对鸣笛之人进行适当的处罚是确保这项规定能够顺利实施的必要举措。&lt;/p&gt;

&lt;p&gt;我们决定利用麦克风阵列获取声音信号，使用 FPGA 技术计算声音的位置， 使用 OPENMV 实现图像的抓拍，最终实现对鸣笛车辆的准确定位。&lt;/p&gt;

&lt;p&gt;1.2 应用领域&lt;/p&gt;

&lt;p&gt;本作品实际应用前景广泛。&lt;/p&gt;

&lt;p&gt;用于民用领域：在交通监控中，对违规鸣笛的车辆进行定位并拍照取证，提高监控效率；在音视频会议系统中，采集会议发言人的语音信号，并进行实时处 理来确定发言人的当前位置坐标；在安防系统中，利用声源定位系统来辅助传统 摄像头，从而调整监控方向，弥补了普通的运动识别在光线昏暗条件下的不足， 提升安防效果；等等。&lt;/p&gt;

&lt;p&gt;用于军事领域：既可以有效的发现敌方目标所在的位置，又可以充分的隐藏 自身。&lt;/p&gt;

&lt;p&gt;1.3 主要技术特点&lt;/p&gt;

&lt;p&gt;（1）采用麦克风阵列来获取声音信号 相较于传统麦克风，麦克风阵列具有空间选择性，能明显抑制干扰；可以用 于获取多个声源或移动声源信号，也可以用在一些特殊场合，该系统对于远处和 近处的声源，均可以正常工作。&lt;/p&gt;

&lt;p&gt;（2）利用 FFT 算法和 CORDIC 算法计算相位 前者是离散傅氏变换（DFT）的快速算法，是有限长序列傅里叶变换的有限 点离散采样，从而实现了频域离散化，使频域采样按照数字运算的方法进行。后者是一个“化繁为简”的算法，将许多复杂的运算转化为一种“仅需要移位和加 法”的迭代操作。&lt;/p&gt;

&lt;p&gt;（3）用 verilog 语言编码并利用 FPGA 实现 本作品用 FPGA 作处理器处理声音信号，利用了 FPGA 硬件并行的优势，在 每个时钟周期内完成更多的处理任务，超越了数字信号处理器的运算能力。&lt;/p&gt;

&lt;p&gt;1.4 关键性能指标&lt;/p&gt;

&lt;p&gt;（1）完成对实验室等室内环境的静止的鸣笛声源定位，并用摄像头以及舵 机云台对鸣笛者进行抓拍，抓拍成功率超过 90%，并且每次抓拍得到的鸣笛者偏 离照片中心不超过 50%.&lt;/p&gt;

&lt;p&gt;（2）完成对实验室等室内环境的缓慢移动的持续鸣笛声源定位，并用摄像 头以及舵机云台对鸣笛者进行跟拍，跟拍成功率超过 90%，并且在跟拍过程中摄 像头内不丢失鸣笛者图像。&lt;/p&gt;

&lt;p&gt;（3）完成对实验室等室内环境的快速移动的持续鸣笛声源定位，并用摄像 头以及舵机云台对鸣笛者进行跟拍，跟拍成功率超过 80%，并且在跟拍过程中摄 像头出现鸣笛者的时间超过跟拍总时间的 80%.&lt;/p&gt;

&lt;p&gt;（4）对上述指标（1）中的抓拍在鸣笛开始的 0.5 秒内完成抓拍&lt;/p&gt;

&lt;p&gt;1.5 主要创新点&lt;/p&gt;

&lt;p&gt;（1）所有过程完全采用数字化的信号处理方式，所有通信均为数字通信， 所有处理的信号都为数字信号，相比于易受各种干扰的模拟信号系统，数字信号 处理抗干扰能力更强，通过多路信号并行处理来实现。&lt;/p&gt;

&lt;p&gt;（2）利用了 FPGA 硬件并行的优势，打破了顺序执行的模式，在每个时钟周 期内完成更多的处理任务，超越了数字信号处理器（DSP）的运算能力。通过使 用尽可能多的麦克风通道，来提高定位的精确度。&lt;/p&gt;

&lt;p&gt;（3）FPGA 良好的运算性能允许建立实时性良好的定位系统，可以做到追踪 高速行驶的鸣笛汽车。&lt;/p&gt;

&lt;p&gt;（4）本项目将定位的空间由原有的二维空间拓展为三维空间，提高了追踪 定位的灵活性和准确性。&lt;/p&gt;

&lt;h2 id=&quot;第二部分-系统组成及功能说明--system-construction--function-description&quot;&gt;第二部分 系统组成及功能说明 / System Construction &amp;amp; Function Description&lt;/h2&gt;

&lt;p&gt;2.1 整体介绍&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/sound_source_dt1.png&quot; alt=&quot;system_diagram&quot; /&gt;
本系统由声源定位系统和图像抓拍系统两部分组成，其中声源定位系统 由麦克风阵列模块、PDM 解码模块、相位计算模块组成，后两个模块通过 FPGA 板实现，图像抓拍系统通过 OPENMV 实现。&lt;/p&gt;

&lt;p&gt;声源产生声音信号，传送给麦克风阵列，编码产生 PDM 波，再通过接收 PDM 波的缓冲区，送入高阶 fir 滤波器实现对 PDM 的解码，然后将结果传入 相位计算模块，即先通过 FFT 算法进行频谱分析，再利用 CORDIC 算法计算 相位得到声源的坐标，最后通过基于 OPENMV 的图像抓拍系统显示声源位置 并抓拍。&lt;/p&gt;

&lt;p&gt;2.2 各模块介绍&lt;/p&gt;

&lt;p&gt;2.2.1 麦克风阵列模块&lt;/p&gt;

&lt;p&gt;我们用到的硅麦型号为 SPW0690LM4H-1，这是一种小型、高性能、低功耗， 底部端口硅数字麦克风与单位 PDM 输出。包括一个声传感器，一个低噪声输入缓冲器和 sigma-delta 调制器。&lt;/p&gt;

&lt;p&gt;它具有的特性：低失真/高 AOP、高信噪比、低功耗模式下低电流消耗、平 坦的频率响应、高驱动能力、射频屏蔽、支持双多路通道、极稳定的性能、全指 向性等等。在采集声音方面，在很宽的频带内增益保持一致，高保真的采集语音 信号，灵敏度高，能够检测到环境中微弱的声音信号。它的全指向性可以拾取各 方向的声音，对来自四面八方的声音同样敏感，特别适合用在本项目中。
&lt;img src=&quot;/OpenHW/assets/images/sound_source_dt2.png&quot; alt=&quot;speaker_inside&quot; /&gt;
&lt;img src=&quot;/OpenHW/assets/images/sound_source_dt4.png&quot; alt=&quot;demo&quot; /&gt;
2.2.2 处理器&lt;/p&gt;

&lt;p&gt;本作品使用 Ego1 开发板作为处理器，型号为 Xilinx Artix-7 系列的 XC7A35T-1CSG324C FPGA。
&lt;img src=&quot;/OpenHW/assets/images/sound_source_dt5.png&quot; alt=&quot;board_overview&quot; /&gt;
&lt;img src=&quot;/OpenHW/assets/images/sound_source_dt6.png&quot; alt=&quot;configuration&quot; /&gt;
Xilinx 7系列的FPGA芯片内部集成了两个12bit位宽、采样率为1MSPS的ADC， 拥有多达 17 个外部模拟信号输入通道，为用户的设计提供了通用的、高精度的 模拟输入接口。
&lt;img src=&quot;/OpenHW/assets/images/sound_source_dt7.png&quot; alt=&quot;XADC_diagram&quot; /&gt;
2.2.3 PDM 解码模块——基于高阶 fir 低通滤波器&lt;/p&gt;

&lt;p&gt;PDM 的解码采用高阶 fir 滤波器的算法。PDM 编码虽然只有 0 和 1 两种电平， 但 PDM 编码保留了原始的未编码数据的所有频率分量，同时增加了高频噪声成 分 FIR 滤波器是数字信号处理系统中最基本的元件，它可以在保证任意幅频特性 的同时具有严格的线性相频特性，其单位抽样响应是有限长的，此系统稳定。根 据自顶向下的层次化、模块化的设计思想，将整个滤波器的设计划分为多个模块， 利用硬件描述语言 Verilog 进行各个模块的功能设计，并用 Matlab 软件设计 98阶滤波器各抽头系数。&lt;/p&gt;

&lt;p&gt;对 PDM 编码进行傅里叶变换，得到的频率响应如下图：
&lt;img src=&quot;/OpenHW/assets/images/sound_source_dt8.png&quot; alt=&quot;PDM_phase_domain&quot; /&gt;&lt;/p&gt;

&lt;p&gt;由于声音定位系统是为了得到人耳可分辨的声音，或得到清晰的骑车鸣 笛声音，并且人耳可以分辨的声音频率为 20-20000Hz，而高于 20000Hz 的声音 信号是我们不需要的，所以我们的低通滤波器的通带频率设置为 0-20000Hz，截 止频率设置为 48000Hz，阻带频率设置为 100000Hz。PDM 信号经过该滤波器， 不仅可以实现 PDM 信号向 PCM 信号的解码，还顺带滤除了我们不需要的高频声 音信号。该 fir 滤波器的差分方程表达式为
&lt;img src=&quot;/OpenHW/assets/images/sound_source_dt9.png&quot; alt=&quot;formula&quot; /&gt;
将原始信号进行编码，并经过 97 阶 fir 低通滤波器的信号与原始信号的对比 图如图 9、10 所示，其中绿色的为解码后的信号，蓝色的为原始信号。
&lt;img src=&quot;/OpenHW/assets/images/sound_source_dt10.png&quot; alt=&quot;comparision&quot; /&gt;
由图可知，设计的滤波器较好的将编码后的信号还原为原始信号，并且原始 信号所包含的频率分量受到的影响较小。&lt;/p&gt;

&lt;p&gt;用 VIVADO 软件编写 verilog 语言实现该 97 阶的数字滤波器，由于需要大量 的串行浮点运算，所以所消耗的时间较多，但通过硬件，可用并行运算进行处理。 通过计算，我们设计的 97 阶滤波器需要 97 个乘法器和 98 个加法器，具体代码 见附录。&lt;/p&gt;

&lt;p&gt;2.2.4 相位计算模块&lt;/p&gt;

&lt;p&gt;（1）通过 FFT 算法进行频谱分析&lt;/p&gt;

&lt;p&gt;FFT 是离散傅氏变换（DFT）的快速算法，是有限长序列傅里叶变换的有限点 离散采样，从而实现了频域离散化，使频域采样按照数字运算的方法进行。&lt;/p&gt;

&lt;p&gt;使用 Xilinx Vivado 内置的 Fast FourierTransform IP core 进行快速傅里叶变换， 配置使用 Radix-2 架构，使用 8 通道,每个通道一帧包含 512 个数据点，如图 11。
&lt;img src=&quot;/OpenHW/assets/images/sound_source_dt11.png&quot; alt=&quot;step1&quot; /&gt;
输入的数据位宽为 16 位，输出则采用 Fixed Point、Unscale，同时为顺序输 出，配置如图 12。
&lt;img src=&quot;/OpenHW/assets/images/sound_source_dt12.png&quot; alt=&quot;step2&quot; /&gt;
3）运用 CORDIC 算法计算相位&lt;/p&gt;

&lt;p&gt;CORDIC 算法是一个“化繁为简”的算法，将许多复杂的运算转化为一种“仅 需要移位和加法”的迭代操作。&lt;/p&gt;

&lt;p&gt;假设在 xy 坐标系中有一个点 P1（x1，y1），将 P1 点绕原点旋转θ角后得到 点 P2（x2，y2）。
&lt;img src=&quot;/OpenHW/assets/images/sound_source_dt13.png&quot; alt=&quot;cordic&quot; /&gt;
于是可以得到 P1 和 P2 的关系：
&lt;img src=&quot;/OpenHW/assets/images/sound_source_dt14.png&quot; alt=&quot;formula&quot; /&gt;
2.2.5 图像抓拍系统&lt;/p&gt;

&lt;p&gt;在本作品中，使用分辨率为 640*480 的以数字图像传感器为核心的摄像头， 并使用具有角度不断变化并可以保持的舵机，构成图像抓拍系统。
&lt;img src=&quot;/OpenHW/assets/images/sound_source_dt15.png&quot; alt=&quot;camera_and_motor&quot; /&gt;&lt;/p&gt;

&lt;p&gt;OPENMV 通过接收 FPGA 串口发送的声源位置信息，从而控制舵机转向声源 的方向，使得我们使用的摄像头可以准确的对准声源，并下达指令给上位机（PC） 进行拍照或录像。照片将存储在上位机的内存中。&lt;/p&gt;

&lt;h2 id=&quot;第三部分-完成情况及性能参数--final-design--performance-parameters&quot;&gt;第三部分 完成情况及性能参数 / Final Design &amp;amp; Performance Parameters&lt;/h2&gt;

&lt;p&gt;（1）完成了在实验室对静止的鸣笛声源进行定位，并用摄像头以及舵机云 台对鸣笛者进行抓拍，抓拍成功率超过 95%，并且每次抓拍得到的鸣笛者偏离照 片中心不超过 30%，抓拍延时在 0.5 秒以内。照片效果如下图所示。
&lt;img src=&quot;/OpenHW/assets/images/sound_source_dt16.png&quot; alt=&quot;photo1&quot; /&gt;
（2）完成对实验室的快速移动的持续鸣笛声源的定位，并用摄像头以及舵 机云台对鸣笛者进行实时跟拍，跟拍成功率超过 80%，并且在跟拍过程中摄像头 出现鸣笛者的时间超过跟拍总时间的 95%，跟拍效果如下图所示
&lt;img src=&quot;/OpenHW/assets/images/sound_source_dt17.png&quot; alt=&quot;photo2&quot; /&gt;
3）上位机屏幕能够实时显示摄像头的情况，并且储存了抓拍到的鸣笛者 照片，以及持续鸣笛跟拍的视频。&lt;/p&gt;
&lt;h2 id=&quot;第四部分-总结--conclusions&quot;&gt;第四部分 总结 / Conclusions&lt;/h2&gt;

&lt;p&gt;4.1 可扩展之处&lt;/p&gt;

&lt;p&gt;（1）我们使用的 4 路数字麦克风阵列 PCB 板预留了额外的 28 个空焊的麦克 风接口，可以扩展至 32 路。从而可以尽可能地减小数字麦克风接收的误码率， 并且再次提高定位的精度。&lt;/p&gt;

&lt;p&gt;（2）我们用来控制舵机云台的 OPENMV 拥有自带的摄像头，并且具有图像 识别等功能，将来可以使用 OPENMV 进行图像处理并配合声源定位系统进行综 合跟拍以及抓拍，从而提高跟拍的成功率以及抓拍的准确度。&lt;/p&gt;

&lt;p&gt;（3）我们使用了高性能的上位机对跟拍和抓拍的图像进行实时显示，并保 存到上位机中。上位机将来可以对保存下来的照片进行二次分析，对抓拍到的车 辆进行车牌识别，并将违章记录上传到云端，并利用大数据进行监管，对一些违 章次数较多的车辆进行处罚。&lt;/p&gt;

&lt;p&gt;（4）本项目使用到的 FPGA 芯片型号仅仅为 XILINX 的 A 系列入门级的 XC7A35T，如果更换为板载资源更多的型号，将会进一步提高声源定位运算的速 度。&lt;/p&gt;</content><author><name>XUP-2020</name></author><category term="project" /><category term="2020competition" /><summary type="html">作者：赵辰宇、白瑞昕、张慈庭</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="/OpenHW/assets/images/sound_source_detection.jpg" /><media:content medium="image" url="/OpenHW/assets/images/sound_source_detection.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">基于 FPGA 的会议系统</title><link href="/OpenHW/meeting-system/" rel="alternate" type="text/html" title="基于 FPGA 的会议系统" /><published>2019-01-28T00:00:00+08:00</published><updated>2019-01-28T00:00:00+08:00</updated><id>/OpenHW/meeting-system</id><content type="html" xml:base="/OpenHW/meeting-system/">&lt;p&gt;作者：薛若尧；周子超；刘朔扬&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/all_white.jpg&quot; alt=&quot;isolution&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;第一部分-设计概述&quot;&gt;第一部分 设计概述&lt;/h1&gt;

&lt;p&gt;1.1 设计目的&lt;/p&gt;

&lt;p&gt;今年，随着疫情的出现，线上会议的应用越来越广泛，相关的技术也越来越 成熟，但当前的线上会议系统大都基于电脑和手机，便于个人使用，但由于其摄 像头拍摄方向固定，当会议一端有多人参与时，就需要每人都单独开一个窗口才 能有较好的效果，较为不便。基于此，我们设计了一个新的会议系统，以更好地 适应多人会议的需求。&lt;/p&gt;

&lt;p&gt;本系统以 Xilinx PYNQ-Z2 FPGA 为控制核心，将声源定位与图像识别相结 合。通过对环境声音的实时检测，实现对声源目标的定位，并基于特征提取和模 式匹配的方法对目标进行图像识别，根据提前训练的数据模型，在显示屏上框出 目标并显示目标的个人信息。同时，也可以通过 socket 通信将识别后的图像信息 直接发送至客户端(PC 机等)显示，从而实现远程会议的效果。&lt;/p&gt;

&lt;p&gt;1.2 应用领域
本系统理念较为新颖，将声源定位与图像识别相结合，并在 FPGA 上实现， 使得系统整体体积与功耗都较小，可以在各种线上会议中使用，在疫情防控常态 化的当下，应用前景十分广泛。例如，该系统可以用于在企业之间进行的大型会 议，声源定位功能可以使摄像头实时跟踪讲话人，并对其进行识别，显示人员信 息，这就使得只使用一个客户端就可以较好地实现多人会议，节省资源；另外， 该系统在多方参与的学术会议或国际会议中也都比较适用。&lt;/p&gt;

&lt;p&gt;1.3 主要技术特点&lt;/p&gt;

&lt;p&gt;（1）采用四麦克风阵列采集声音信息，并通过硬件电路将麦克风阵列输出 PDM 信号直接转换为 I2S 信号送入 FPGA 中处理。&lt;/p&gt;

&lt;p&gt;（2）使用 python 编写的 TDOA 算法进行声源定位，即先通过 GCC-PHAT 算法 得出不同麦克风芯片接收到声音的时延，再通过几何关系计算出声源所在的角度。&lt;/p&gt;

&lt;p&gt;（3）采用 Haar 特征提取算法检测人脸区域，速度快，识别率较高；采用 LBPH 特征识别算法对数据集中的图片进行训练，训练完成后，建立标签与真实人员姓 名的直接映射表，从而实现身份识别。&lt;/p&gt;

&lt;p&gt;（4）基于 socket 通信，使用 UDP 通信协议，将图像从 FPGA 中实时传输到客户 端 (PC 机等)中显示，从而实现远程会议的功能。&lt;/p&gt;

&lt;p&gt;1.4 关键性能指标&lt;/p&gt;

&lt;p&gt;（1）声源定位速度与准确率 本系统在环境噪声较小的情况下可在 1 秒之内完成声源定位，准确率几乎为 100%；在环境噪声较大的情况下定位时间会稍长，在 2 秒左右也基本可以完成 定位，准确度在 90%以上。&lt;/p&gt;

&lt;p&gt;（2）人脸检测与身份识别速度与准确率 本系统人脸检测速度较快，当人脸进入摄像头中部区域后就可立即框出 人脸，在摄像头中部区域人脸检测准确率几乎为 100%；身份识别速度较人脸检 测稍慢，但识别时间都在 0.5s 左右，当人员处于拍摄区域中部时识别准确率较 高，在 90%以上，当人员处于拍摄区域边缘时准确度较低，但也基本都在 80%以 上。&lt;/p&gt;

&lt;p&gt;（3）数据无线传输速率与延时 本系统无线数据传输时，客户端(PC)接收到图像信息的延时在 1s 左右，延时 较低；其传输速率也较快，显示的图像基本都在 3 帧/秒以上。&lt;/p&gt;

&lt;p&gt;1.5 主要创新点&lt;/p&gt;

&lt;p&gt;（1）采用了数字麦克风芯片，抗干扰能力较强，且在使用时外围电路简单；使 用四芯片麦克风阵列采集声音信号，使得其在 360°平面内对声源方向角度的分 辨率大大提高。&lt;/p&gt;

&lt;p&gt;（2）采用 AC108 芯片将 PDM 信号转换为 I2S 信号，再送入 FPGA 中处理。&lt;/p&gt;

&lt;p&gt;（3）采用 TDOA 算法，并在高速、并行的 FPGA 中实现，使得声源定位的速度 较快，延迟较低。&lt;/p&gt;

&lt;p&gt;（4）使用舵机搭建了水平 360°云台，使摄像头可以更方便地跟踪声源。&lt;/p&gt;

&lt;p&gt;（5）系统支持现场录入人员并学习，且识别率较高。&lt;/p&gt;

&lt;p&gt;（6）基于 socket 通信，实现将图像信息从 FPGA 中实时传输到客户端(PC 机等) 显示的功能。&lt;/p&gt;

&lt;p&gt;（7）该会议系统功耗低、体积小、易安装并且可供多人在同一客户端使用。&lt;/p&gt;

&lt;h1 id=&quot;第二部分-系统组成及功能说明&quot;&gt;第二部分 系统组成及功能说明&lt;/h1&gt;

&lt;p&gt;2.1 整体介绍&lt;/p&gt;

&lt;p&gt;本系统由麦克风阵列模块、FPGA 处理器模块、摄像头模块、远程数据传输 模块和显示模块共同组成。麦克风阵列模块在检测声音信号后，将转换后的 PCM 码送入 FPGA 处理器模块处理，实现对声源目标的定位；摄像头模块在接收到 FPGA 处理器模块发出的位置信号后，控制摄像头转向声源方向，并将摄像头拍 摄到的图像信息传入 FPGA 处理器模块进行处理，识别其是否为检测目标，若为 检测目标则显示检测到的人员信息；若没有检测到相关目标，则重新进行声源定 位。图 2.1 为系统整体框图。
&lt;img src=&quot;/OpenHW/assets/images/meeting_system/system_diagram.png&quot; alt=&quot;system_diagram&quot; /&gt;&lt;/p&gt;

&lt;p&gt;2.2 各模块介绍&lt;/p&gt;

&lt;p&gt;2.2.1 麦克风阵列模块&lt;/p&gt;

&lt;p&gt;系统采用由 KNOWLES 公司制造的性能优良的 MEMS 数字麦克风芯片 SPU0414HR5H，可识别频率在 100Hz~10kHz 范围内的声音信号。选用四芯片麦 克风阵列采集声音信号，输出四路 PDM 信号到 AC108 芯片中进行解调，输出 PCM 信号送入 FPGA 中进行处理。数字麦克风阵列电路原理图见附录图 1，图 2，其实物图如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/meeting_system/microphone_array.png&quot; alt=&quot;micro_aaray&quot; /&gt;&lt;/p&gt;

&lt;p&gt;2.2.2 FPGA 处理器模块&lt;/p&gt;

&lt;p&gt;处理器模块主要采用 Xilinx PYNQ-Z2 开发板，其由 650MHz 双核 Coryex-A9 处理器与 FPGA 组成。PYNQ-Z2 开发板支持 Python 语言开发，也支持使用传统 的 Xilinx Vivado 开发工具流程平台开发编写 Verilog 来开发嵌入式系统应用。同 时，PYNQ-Z2 开发板也具有极其丰富的外设接口，如千兆以太网口、USB 接口、 UART 接口、HDMI 输出/输出接口等常用接口，还提供了兼容 Ardunio、RPi、 Pmod 的扩展接口。&lt;/p&gt;

&lt;p&gt;声源定位算法和图像识别的算法均在处理器模块中实现。&lt;/p&gt;

&lt;p&gt;（1）TDOA 声源定位算法&lt;/p&gt;

&lt;p&gt;TDOA 定位算法是一种利用时间差进行定位的方法，通过测量信号到达的时 间，可以确定信号源的距离，利用信号源到各个信号接受点的距离，就能确定信 号的位置。采用 GCC-PHAT 算法，先对输入 FPGA 中的 PCM 信号通过 I2S 协议 采样，得到四路数字信号，以两个信号为一组，采用广义互相关的方法求出时延， 即求两路信号的互频谱，得出其频谱峰值索引，即为声音到这两路信号采集点的 时延。得到时延后，根据几何关系，即可求出声源与两对角信号采集点连线的角 度，进而得到摄像头需要旋转的角度信息。&lt;/p&gt;

&lt;p&gt;（2）Haar 特征提取算法&lt;/p&gt;

&lt;p&gt;系统使用 Haar 特征提取的识别算法进行人脸检测。Haar 特征提取过程是将 一副图像中所有黑色矩形框和白色矩形框中所包含的全部像素进行差值运算，得 到该图像的 Haar 特征值，但由于一副图像中包含的 Haar 特征的个数较多，对于其中矩形特征的特征值的提取相对比较复杂，因此采用积分图像的转换来缩减其 计算量，以提高运算速度。&lt;/p&gt;

&lt;p&gt;在提取出 Haar 特征后，将其分别转化为弱分类器，然后根据弱分类器处理 样本数据，根据其正确分类样本的情况来改变其权值大小，进而产生多个强分类 器，然后将这些训练产生的强分类器继续迭代，最终获得一个识别率较高的最终 强分类器，从而实现对人脸区域的准确识别。&lt;/p&gt;

&lt;p&gt;（3）LBPH 特征识别算法&lt;/p&gt;

&lt;p&gt;系统采用了基于 LBP(局部二值模式)特征的 Adaboost(级联分类器)进行人脸 识别。LBP 是典型的二值描述算子，其更多的是整数计算，可以通过各种逻辑操 作对运算过程进行优化，因此效率较高。此外，通常光照对图像中物体的影响是 全局的，即图像中物体的明暗程度通常是往同一个方向改变的，只是改变的幅度 会因距离光源的远近而有所不同，故图像中局部相邻的像素间受光照影响后的相 对大小不会改变，LBP 特征也因此对光照具有比较好的鲁棒性。Adaboost 是一种 迭代算法，其核心思想是针对同一个训练集训练不同的弱分类器，然后把这些弱 分类器集合起来，构成一个更强的最终分类器。Adaboost 算法系统具有较高的 检测速率，且不易出现过适应现象。&lt;/p&gt;

&lt;p&gt;2.2.3 摄像头模块&lt;/p&gt;

&lt;p&gt;采用 GUCEE 摄像头，1200 万像素，动态分辨率支持 1920*1080，其机身小 巧，易于安装，适合在各种环境下使用。同时，系统搭建了一个摄像头云台，使 用一个舵机来控制云台上摄像头的转向，使其能在水平 360°范围内跟踪声源方位。&lt;/p&gt;

&lt;p&gt;2.2.4 远程数据传输模块&lt;/p&gt;

&lt;p&gt;系统基于 socket 通信，编写 python 创建 UDP 服务端程序，在同一局域网下 可以将图像信息直接从 FPGA 中发送到任一客户端(PC 机等)中，客户端只需打 开使用 python 编写好的上位机程序，即可接收到信息并同步显示。其无线传输 延迟较小，传输速度较快且输出图像较为清晰。 2.2.5 显示模块 采用 Creatblock7 寸 iPS 高清显示屏，使用 FPGA 中的显示模块将识别后的 图像直接显示在显示屏上。&lt;/p&gt;

&lt;h1 id=&quot;第三部分-完成情况及性能参数&quot;&gt;第三部分 完成情况及性能参数&lt;/h1&gt;

&lt;p&gt;3.1 声源定位&lt;/p&gt;

&lt;p&gt;系统可较好实现 360°声源定位，在环境噪声较小的情况下，识别很精准， 误差不超过 5°，在有一定噪声干扰的情况下，其识别度也能稳定在一定水平， 识别误差不超过 15%。下表为声源定位测试结果：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/meeting_system/sound_source_detection.png&quot; alt=&quot;results&quot; /&gt;
3.2 身份识别与显示&lt;/p&gt;

&lt;p&gt;系统能够很好地实现人脸检测与身份识别功能，且运算速度较快，在识别到 人脸后能够迅速框出人脸，并将其人脸特征与数据库中录入特征进行匹配，若匹 配到相应的人脸信息则直接在方框上方显示当前人员信息，若未匹配到相应人脸 信息，则只框出人脸。人脸检测识别率很高，识别速度较快；身份识别速度较快， 在单人识别时成功率较高，达到 90%以上，当同时有多人在识别范围内时识别准 确度会受到影响，但也基本在 80%以上。识别后的图像可以清晰地在显示屏上显 示，并且显示延迟较小。下图为人脸检测与身份识别显示画面：
&lt;img src=&quot;/OpenHW/assets/images/meeting_system/exp1.png&quot; alt=&quot;show1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;3.3 无线数据传输&lt;/p&gt;

&lt;p&gt;系统通过 socket 通信，可以将图像信息直接通过局域网传输到客户端中，这 里使用 PC 机作为客户端，在运行上位机程序后即可接收到从 FPGA 中实时传输的图像。通过 FPGA 上的拨码开关可以控制传输图像的模式，即实时显示模式和 身份识别模式。下图为 PC 机接收到的图像：
&lt;img src=&quot;/OpenHW/assets/images/meeting_system/exp2.png&quot; alt=&quot;show2&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;第四部分-总结&quot;&gt;第四部分 总结&lt;/h1&gt;

&lt;p&gt;4.1 可扩展之处&lt;/p&gt;

&lt;p&gt;（1）当前系统声源定位在特定位置处定位误差会略大，同时，在环境噪音较大 的情况下，也会对声源定位造成一定影响。可通过增加麦克风数量，改变麦克风 阵列结构或改进声源定位算法等进一步提高系统声源定位的精度与抗干扰性。&lt;/p&gt;

&lt;p&gt;（2）拓展图像处理功能，将摄像头拍到的图像降噪，并根据图像的具体情况自 动将图像的亮度和对比度等特性调节到合适的值。&lt;/p&gt;

&lt;p&gt;（3）当前系统无线数据传输功能只能将FPGA拍摄到的图像数据发送到和FPGA 连接在同一局域网内的客户端中，可以进一步完善无线传输功能，使得 FPGA 可 以直接将图像数据发送到外网的客户端中，增加系统的实用性。&lt;/p&gt;

&lt;p&gt;（4）优化图像处理算法，进一步提高人脸识别算法的准确度与鲁棒性。&lt;/p&gt;</content><author><name>XUP-2020</name></author><category term="project" /><category term="2020competition" /><category term="featured" /><summary type="html">作者：薛若尧；周子超；刘朔扬</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="/OpenHW/assets/images/meeting_system/cover.jpg" /><media:content medium="image" url="/OpenHW/assets/images/meeting_system/cover.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">基于 YOLO 算法的扫描式 SMT 焊点缺陷检测系统</title><link href="/OpenHW/YOLO_SMT/" rel="alternate" type="text/html" title="基于 YOLO 算法的扫描式 SMT 焊点缺陷检测系统" /><published>2019-01-27T00:00:00+08:00</published><updated>2019-01-27T00:00:00+08:00</updated><id>/OpenHW/YOLO_SMT</id><content type="html" xml:base="/OpenHW/YOLO_SMT/">&lt;p&gt;作者：肖鹏；桓永犇；刘宏扬&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/all_white.jpg&quot; alt=&quot;isolution&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;第一部分-设计概述&quot;&gt;第一部分 设计概述&lt;/h1&gt;

&lt;p&gt;1.1 设计目的&lt;/p&gt;

&lt;p&gt;作为电子产品最重要的组成部分，印刷电路板（PCB）的设计日趋复杂和器件尺寸的缩小，促使对 SMT 可靠性提出了更高的要求[1]。因此对于 SMT 电路板的检测研究具有深刻的现实意义和经济价值。&lt;/p&gt;

&lt;p&gt;在 SMT 工艺中，贴片器件焊点的好坏会严重影响 PCB 板的质量。轻则会导致可靠性下降，重则可能导致电路烧毁。为了能够确保将 PCB 板应用到高质量、 高可靠性的电子产品中，提高产品合格率，对焊点的缺陷检测是十分必要的[2]。&lt;/p&gt;

&lt;p&gt;1.2 应用领域&lt;/p&gt;

&lt;p&gt;本作品属于 SMT 工艺检测中的焊点检测领域，可区分良好焊点以及虚焊漏焊、短路、多锡、偏移等缺陷焊点情况。&lt;/p&gt;

&lt;p&gt;作品可应用于小型的 SMT 贴片厂对批量 PCB 电路的焊点可靠性进行检测，或者电子维修领域对电路板进行辅助分析观察，同样也可在个人开发者对焊接电路的检测，相比传统方法可以大大降低人力和设备成本。&lt;/p&gt;

&lt;p&gt;1.3 主要技术特点&lt;/p&gt;

&lt;p&gt;目前，在国内外印刷电路板焊点质量检测的主要方法有：人工目测、自动光学检测、自动射线检测等方法[2]。&lt;/p&gt;

&lt;p&gt;人工目测法是目前最简单的方式，但受检测员主观性影响较大，且检测速度低、错误率高[3]。&lt;/p&gt;

&lt;p&gt;自动光学检测法（AOI）采用 CCD 摄影的形式获取元件和印刷电路板的图像，可实现自动化检测，但仪器成本较高，往往需数十万元。&lt;/p&gt;

&lt;p&gt;自动射线检测（AXI）采用 X 光对 PCB 板进行扫描，可对球栅阵列（BGA） 等封装进行检测，但价格相比 AOI 仪器更加昂贵。&lt;/p&gt;

&lt;p&gt;本作品采用基于机器视觉的检测方式，模拟人类视觉的智能行为，把所需要的信息从图像中提取、处理和分析，其具有成本低、抗干扰性强、鲁棒性强、可有效处理无规律和复杂背景缺陷等特点。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/YOLO_SMT/introduction.png&quot; alt=&quot;introduction&quot; /&gt;&lt;/p&gt;

&lt;p&gt;1.4 关键性能指标&lt;/p&gt;

&lt;p&gt;机械位移系统参数：&lt;/p&gt;

&lt;p&gt;电源额定电压：24V&lt;/p&gt;

&lt;p&gt;电源额定电流：6A&lt;/p&gt;

&lt;p&gt;电机运行速度范围：5mm/s—80mm/s&lt;/p&gt;

&lt;p&gt;步距角：1.8°&lt;/p&gt;

&lt;p&gt;最小运动距离：25um&lt;/p&gt;

&lt;p&gt;丝杆有效行程：200mm&lt;/p&gt;

&lt;p&gt;丝杆螺距：5mm&lt;/p&gt;

&lt;p&gt;PCB 板扫描时间：T&amp;lt;40s （在 100mm*100mm PCB 以 50mm/s 扫描速度下测得）&lt;/p&gt;

&lt;p&gt;成像系统参数：&lt;/p&gt;

&lt;p&gt;摄像头像素：500w 像素&lt;/p&gt;

&lt;p&gt;摄像头帧率：30 帧/s&lt;/p&gt;

&lt;p&gt;物镜：0.7x-4.5x&lt;/p&gt;

&lt;p&gt;目镜：0.35x Yolov3&lt;/p&gt;

&lt;p&gt;算法参数： mAP&lt;/p&gt;

&lt;p&gt;平均精度(mean Average Precision)：84.3%&lt;/p&gt;

&lt;p&gt;Yolo loss：11.2&lt;/p&gt;

&lt;p&gt;处理速度：10fps/s（基于 zynq ultrascale 开发板部署下每秒预测图片的速度）&lt;/p&gt;

&lt;p&gt;1.5 主要创新点&lt;/p&gt;

&lt;p&gt;（1）YOlO 算法相比于 R-CNN 等算法对算力要求更小、运行速度更快，适合在 FPGA 上进行部署，且其有着较好的泛化能力[4][5]，能有效减少背景错误。&lt;/p&gt;

&lt;p&gt;（2）基于机器视觉的检测方式，相比于传统 AOI 光学检测方法，其对复杂背景下缺陷检测识别效果更好，抗干扰能力更强[6]。&lt;/p&gt;

&lt;p&gt;（3）不受限于缺陷本身形态，不依赖手工规则，可对算法进行迭代复用。&lt;/p&gt;

&lt;p&gt;（4）可对 PCB 板进行全自动扫描，实时在显示屏和 PC 上位机上显示，保存缺陷焊点图片及坐标位置。并对感兴趣的缺陷焊点进行溯回，将其移动至摄像头下观察。&lt;/p&gt;

&lt;h1 id=&quot;第二部分-系统组成及功能说明&quot;&gt;第二部分 系统组成及功能说明&lt;/h1&gt;

&lt;p&gt;2.1 整体介绍&lt;/p&gt;

&lt;p&gt;我们的系统主要由光学成像部分、图像处理部分，机械控制部分及人机交互界面四个部分组成。&lt;/p&gt;

&lt;p&gt;光学成像部分主要由三维可调相机支架、USB 摄像头、目镜物镜和可调圆形光源组成。&lt;/p&gt;

&lt;p&gt;图像处理部分则通过一块 zynq ultrascale 开发板连接摄像头，在 PL 端部署 yolov3 神经网络，将摄像头传回的图片进行焊点检测，通过 7 寸 HDMI 显示屏显示处理标注后的图片，并将有缺陷的焊点图片通过TCP协议传输至PC上位机。&lt;/p&gt;

&lt;p&gt;机械控制部分则由一块 PYNQ 开发板、42 步进电机、驱动电路板、限位器和双轴滑台组成，同样通过 TCP 协议与上位机进行指令和数据传输，控制位移平台运动。&lt;/p&gt;

&lt;p&gt;人机交互界面则是在 PC 上采用 PyQT 进行界面编写，作为 TCP 服务端，通过一个交换机将两块开发板连接在同一局域网下，实现协同操作。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/YOLO_SMT/system_diagram.png&quot; alt=&quot;introduction&quot; /&gt;&lt;/p&gt;

&lt;p&gt;2.2 各模块介绍&lt;/p&gt;

&lt;p&gt;2.2.1 光学成像部分&lt;/p&gt;

&lt;p&gt;光学成像部分主要由三维可调相机支架、USB 摄像头、目镜物镜和可调圆形光源组成，示意图如下图所示。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/YOLO_SMT/optical_achi.png&quot; alt=&quot;optical_chi&quot; /&gt;&lt;/p&gt;

&lt;p&gt;USB 摄像头采用型号 XGY300 的免驱彩色摄像头，CMOS 传感器大小为 1/2 英寸，像素大小为 300w，物镜为 0.7x-4.5x，目镜为 0.35x，放大倍数在 3-130 倍可调。&lt;/p&gt;

&lt;p&gt;2.2.2 机械控制部分&lt;/p&gt;

&lt;p&gt;电机控制部分硬件结构由 PYNQ、42 步进电机、驱动器、双轴导轨滑台、限位器和光耦组成。软件部分由上位机与 PYNQ 通过 TCP 协议通信完成对应控制。&lt;/p&gt;

&lt;p&gt;整体结构如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/YOLO_SMT/achitecture.png&quot; alt=&quot;achitecture&quot; /&gt;&lt;/p&gt;

&lt;p&gt;软件流程如下图所示：
&lt;img src=&quot;/OpenHW/assets/images/YOLO_SMT/tcp_flow.png&quot; alt=&quot;tcp_flow&quot; /&gt;&lt;/p&gt;

&lt;p&gt;(a)硬件设计&lt;/p&gt;

&lt;p&gt;整体硬件 PCB 设计如下图所示：
&lt;img src=&quot;/OpenHW/assets/images/YOLO_SMT/pcb_design.png&quot; alt=&quot;pcb_design&quot; /&gt;&lt;/p&gt;

&lt;p&gt;电机驱动部分设计&lt;/p&gt;

&lt;p&gt;A4988 是一款完整的微步电机驱动器，内置转换器，操作简便。它设计用于以全步，半步，四分之一，八分之一和十六分之一步模式操作双极步进电机，输出驱动能力高达 35V 和±2A 电流。A4988 包括一个固定的关断时间电流调节器， 能够在慢速或混合衰减模式下工作。细分驱动是减小步距角、提高步进分辨率、 增加电机运行平稳性的一种行之有效的方法，本设备使用 16 细分，能够满足高精密定位的要求。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/YOLO_SMT/motor_driver.png&quot; alt=&quot;motor_driver&quot; /&gt;&lt;/p&gt;

&lt;p&gt;光耦检测电路设计&lt;/p&gt;

&lt;p&gt;光耦选用 6N137，输入 0~24V，输出 0~3.3V，采用共阴极接法。当金属滑台靠近限位器时，限位器信号线输出高电平，使光耦打开，PYNQ 引脚被置位， 作为电机停止信号。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/YOLO_SMT/circuitq.png&quot; alt=&quot;circuit1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;（b）机械部分设计：&lt;/p&gt;

&lt;p&gt;电机部分选用两相式 42 步进电机，其步距角为 1.8°，额定电流为 1.5A， 力矩为 0.7Nm。&lt;/p&gt;

&lt;p&gt;采用双轴导轨滑台，可在 X 轴、Y 轴方向移动，有效行程均为 200mm，单圈行程为 5mm。&lt;/p&gt;

&lt;p&gt;限位器选用 SN04-P 金属传感器固定在滑台上，额定工作电压为 10~30V， PNP 常开，有效输出信号为高电平，测量距离为 5mm，用以对控制电机起始位置。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/YOLO_SMT/picture1.png&quot; alt=&quot;picture1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;（c）软件指令设计：&lt;/p&gt;

&lt;p&gt;上位机通过 TCP 协议发送指令给 PYNQ，从而控制电机对待检测 PCB 进行复位、十字扫描、定位以及实时获取坐标等操作。指令格式如下表：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/YOLO_SMT/tcp_command.png&quot; alt=&quot;tcp_command&quot; /&gt;&lt;/p&gt;

&lt;p&gt;2.2.3 图像处理部分&lt;/p&gt;

&lt;p&gt;（a）焊点情况分类&lt;/p&gt;

&lt;p&gt;焊点情况的分类如下图所示，包含正常、多锡、少锡、漏焊、短路、偏移六种情况。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/YOLO_SMT/classification.png&quot; alt=&quot;classification&quot; /&gt;&lt;/p&gt;

&lt;p&gt;（b）数据集标注&lt;/p&gt;

&lt;p&gt;数据集采用 labelImg 软件进行标注，对应英文名称如下&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/YOLO_SMT/labeling.png&quot; alt=&quot;labeling&quot; /&gt;&lt;/p&gt;

&lt;p&gt;c）YOLO 算法介绍&lt;/p&gt;

&lt;p&gt;YOLO 是一种采用卷积神经网络(CNN)实现端到端目标检测的算法。其运用回归的思想，将目标检测看成是一个回归的问题，能够实时预测多个目标的类别和目标边框的位置，另外 YOLO 采用滑动窗口的方式寻找目标，与传统的基于候选区域方式不同，它直接利用整幅图片训练网络模型。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/YOLO_SMT/YOLO_alg.png&quot; alt=&quot;YOLO_alg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;YOLO 经过不断改进已经从 YOLOv1 发展到 YOLOv5，本系统搭载的 YOLOv3 网络模型由骨干网络 Darknet-53 和 YOLO 检测层组成[8]，骨干网络主要从图像中提取特征，YOLO 层用来预测类别和位置信息，Darknet-53 有 5 个不同尺度和深度的残差模块，每个残差模块借鉴 Resnet 结构，由一对连续的 3×3、1×1 卷积层和跳层连接组成，克服梯度消失以及精度下降问题，增强了特征表达能力。其神经网络结构如下图所示。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/YOLO_SMT/YOLO_network.png&quot; alt=&quot;YOLO_network&quot; /&gt;&lt;/p&gt;

&lt;p&gt;（d）焊点识别的训练过程：&lt;/p&gt;

&lt;p&gt;制作数据集：&lt;/p&gt;

&lt;p&gt;在待检测的板子上通过灰度处理，高斯模糊和调节摄像头放大尺寸的方法拍摄 300 多张照片，并进行标注。将百分之九十五的图片处理为训练集，剩下百分之五的图片为测试集。&lt;/p&gt;

&lt;p&gt;图像增强：&lt;/p&gt;

&lt;p&gt;将输入图片的数据进行归一化，使用（以 R 为例）的方式，并且在训练预处理和拍摄过程都加入了一定程度的高斯噪声，以期待将光照强度对于 pcb 检测的影响降到最低。&lt;/p&gt;

&lt;p&gt;训练过程：&lt;/p&gt;

&lt;p&gt;在训练最好的模型之前。我们对于 100 多张 pcb 图片的数据集进行过两次训练。在迭代 200-300 次左右（基础学习率为 2.5e-06）训练结果不太理想（loss 仅 为 45）。在最后一次训练，选择迭代 3000 次，基础学习率为 0.0025 在第 500 次 1500 次 2500 次中学习率以 10 的倍率衰减三次，从而获得比较满意的结果 （loss=9.7，mAP=0.95）（测试集）&lt;/p&gt;

&lt;p&gt;2.2.4 上位机部分&lt;/p&gt;

&lt;p&gt;软件界面采用交互式界面设计风格进行设计[9]，使用户可以方便简洁地通过界面接收图像、控制电机、获得可视化结果，并可在软件界面中对检测最终结果进行展示。&lt;/p&gt;

&lt;p&gt;PyQt 是 Python 中用来建立图形化用户界面的库，它具有 300 多个类和约 6000 个函数，目前 PyQt 可用的版本己更新至 PyQt5，其优势之一在于可以在所有主要计算机操作系统上运行，如 Mac，Unix 和 Windows。PyQt 在使用上完全继承了 Python 易学易用的特点，非常适合非计算机专业的科研人员使用。&lt;/p&gt;

&lt;p&gt;本系统按照前几节中对软件功能需求的详细分析进行界面功能的具体实现， 使用 Pyqt5 设计的 GUI 界面如下图所示。
&lt;img src=&quot;/OpenHW/assets/images/YOLO_SMT/qt.png&quot; alt=&quot;qt&quot; /&gt;&lt;/p&gt;

&lt;p&gt;该界面主要由三大部分组成，左侧部分通过 TCP 协议与 Zynq ultrascale 开发板通信，负责接收带有缺陷焊点的图片数据、接收或发送文本数据，主要包括连接和断开连接按钮、缺陷溯回按钮以及接收和发送信息按钮。&lt;/p&gt;

&lt;p&gt;中间部分通过 TCP 协议发送相关指令给 PYNQ，使其控制电机运动，实现目标板图像数据的采集，共有复位、坐标询问、十字扫描、手动移动、缺陷溯回五大功能。&lt;/p&gt;

&lt;p&gt;右侧用于输出日志信息，方便观察系统整体状态。&lt;/p&gt;

&lt;h1 id=&quot;第三部分-完成情况及性能参数&quot;&gt;第三部分 完成情况及性能参数&lt;/h1&gt;

&lt;p&gt;3.1 系统架构完成情况&lt;/p&gt;

&lt;p&gt;光学成像部分已完全搭建完毕，通过夹具固定摄像头器件，并可对摄像头进行两个维度的手动调节，在物镜下安装了一个可调白光光源用于照明。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/YOLO_SMT/Optical1.png&quot; alt=&quot;Optical1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;机械控制部分目前已全部完成并进行了制板及测试，可实现对两个电机协同控制，以及接近开关信号的检测，其实物图如下所示。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/YOLO_SMT/Optical2.png&quot; alt=&quot;Optical2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上位机部分已经完成与机械控制系统的联调，可通过上位机实现共有复位、 坐标询问、十字扫描及手动移动功能，目前正在开发对网络图像的实时传输和缺陷溯回功能。&lt;/p&gt;

&lt;p&gt;图像处理部分目前已将 YOLO 神经网络算法部署至 ZYNQ Ultrascale 开发板 上，可正常进行摄像头读取、检测焊点图片并对各类焊点进行标注，通过 HDMI 显示屏输出处理后图片。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/YOLO_SMT/zynq_ultra1.png&quot; alt=&quot;zynq_ultra1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;3.2 算法测试情况&lt;/p&gt;

&lt;p&gt;我们对 PCB 板进行放大拍摄并做灰度处理，再对处理后的图片进行标注制作成数据集送入神经网络训练，以下为在测试集上的测试结果：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/YOLO_SMT/test.png&quot; alt=&quot;test&quot; /&gt;&lt;/p&gt;

&lt;p&gt;根据测试结果，基本可以完成对焊点缺陷的检测，且置信度较高，但仍存在漏检的情况，后续需要对算法进一步优化以及对数据集进行补充。&lt;/p&gt;

&lt;h1 id=&quot;第四部分-总结&quot;&gt;第四部分 总结&lt;/h1&gt;

&lt;p&gt;4.1 可扩展之处&lt;/p&gt;

&lt;p&gt;本作品目前已初步完成功能，预计在之后作品可进行如下扩展：&lt;/p&gt;

&lt;p&gt;（1）收集各类 PCB 板，针对不同封装下各类焊点，制作更多的数据集， 提升算法精度。&lt;/p&gt;

&lt;p&gt;（2）考虑和物联网进行结合，检测数据的同时上传焊点图片，减小人工的工作量，进一步获取更多数据。&lt;/p&gt;

&lt;p&gt;（3）尝试采用其他机器学习算法，如 SSD 算法等进行实验，寻找更优的机器学习算法&lt;/p&gt;

&lt;p&gt;（4）考虑针对复杂 PCB 场景下（如电脑、手机主板），它们芯片封装往往焊点不露出，可增加红外摄像头或 X-ray 方式获取焊点图片&lt;/p&gt;

&lt;p&gt;（5）为进一步提升检测的准确性，可以考虑采用 3D 系统设备&lt;/p&gt;

&lt;p&gt;（6）增加更多视觉方面的检测（如 PCB 表面清洁程度等）&lt;/p&gt;

&lt;p&gt;（7）优化机械结构，选用更优的摄像头，提升检测图像稳定性。&lt;/p&gt;</content><author><name>XUP-2020</name></author><category term="project" /><category term="2020competiton" /><summary type="html">作者：肖鹏；桓永犇；刘宏扬</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="/OpenHW/assets/images/YOLO_SMT/cover.jpg" /><media:content medium="image" url="/OpenHW/assets/images/YOLO_SMT/cover.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">基于 FPGA 的遥感图像智能处理系统</title><link href="/OpenHW/remote-sensing-2020/" rel="alternate" type="text/html" title="基于 FPGA 的遥感图像智能处理系统" /><published>2019-01-26T00:00:00+08:00</published><updated>2019-01-26T00:00:00+08:00</updated><id>/OpenHW/remote-sensing-2020</id><content type="html" xml:base="/OpenHW/remote-sensing-2020/">&lt;p&gt;作者：张宁 李铿 曹云飞&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/all_white.jpg&quot; alt=&quot;isolution&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;第一部分-设计概述&quot;&gt;第一部分 设计概述&lt;/h1&gt;

&lt;p&gt;1.1 设计目的&lt;/p&gt;

&lt;p&gt;近些年随着人工智能技术的发展，深度神经网络算法逐步在星载、机载等遥感数据处理中得到广泛应用，在灾害预警及应急、海洋应用、环境监测、国土资源等方面起到越来越重要的作用[1]，如图 1 所示。但卫星、无人机等需要对遥感 图像进行实时处理的应用场景，都对实现平台具有严格的体积、重量、功耗的限制。而深度神经网络又具有运算复杂度高、存储带宽需求大的特点[2]。在高时效性要求与资源功耗等空间环境的强约束下，通用处理平台难以支撑在轨人工智能 应用的计算需求。这都使得人工智能技术在上述领域应用面临着巨大的挑战。因此亟需开展支持星载、机载人工智能应用的核心硬件与基础软件技术研究。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/remote_sensing/bri_application.png&quot; alt=&quot;bri_application&quot; /&gt;&lt;/p&gt;

&lt;p&gt;为了解决上述问题，我们提出了基于 FPGA 的深度卷积神经网络的核心硬件系统架构，并基于此架构搭建了遥感图像智能处理系统。该系统具有高性能、低功耗、延时低等特点，可以为空间人工智能应用提供支撑。&lt;/p&gt;

&lt;p&gt;1.2 应用领域&lt;/p&gt;

&lt;p&gt;本作品在 FPGA 上实现了改进后的 YOLOv2 目标检测网络[3]，能够完成对遥感场景下飞机、汽车、港口等多尺度、多类型目标的高精度快速检测及分类，在海洋、水旱等监测与应急救灾等多领域中都可以发挥重要作用。 此外，本作品相比于与 CPU、GPU 通用处理平台功耗更低，并且具有同等功率下运行效率高（能效比高）等优势。在星载、机载等资源受限的条件下，作品可以满足深度神经网络的庞大的计算量与存储需求，为遥感图像的在线处理提供了可能。 同时，本作品为我们后续研制相关 ASIC 芯片提供了前端验证。卫星所获取到的遥感图像可以通过该芯片完成在轨实时处理，仅将有效信息下发地面站，从而减少星地链路的传输压力。&lt;/p&gt;

&lt;p&gt;1.3 主要技术特点&lt;/p&gt;

&lt;p&gt;本作品提出了一种用于光学遥感目标智能检测识别的 FPGA 实现方法。&lt;/p&gt;

&lt;p&gt;首先，我们选取 YOLOv2 作为基础网络，对该网络的结构进行了优化。改进后的网络在多尺度、多类型目标的遥感图像处理任务中表现出更优的性能。并引入了基于对称量化的混合精度运算，降低了网络中的浮点运算规模，使该网络更 适合部署在 FPGA 硬件平台上。&lt;/p&gt;

&lt;p&gt;其次，我们提出了一种卷积神经网络处理引擎，该引擎可以实现卷积神经网络中常见的操作，例如卷积、激活、池化等。该引擎还可以实现网络中所涉及到 的多种卷积类型。在此基础上，我们充分挖掘神经网络中卷积运算的并行运算潜力，搭建运算流水线结构，提高了处理性能。此外，我们还提出了一种有效的数据存储和访问策略，该策略可实现低延迟计算和高存储带宽利用率。&lt;/p&gt;

&lt;p&gt;最后，我们成功在 Xilinx VC709 上部署了改进的 YOLOv2 网络。与传统实 现平台相比，该作品在保证检测精度的同时，极大地降低了功耗和运算复杂度， 更加适合部署在低功耗应用场景。&lt;/p&gt;

&lt;p&gt;1.4 主要创新点&lt;/p&gt;

&lt;p&gt;(1) 面向 FPGA 对算法进行优化。采用混合精度神经网络处理方法，利用低位宽的整数运算对部分浮点运算进行近似，从而优化硬件结构，降低逻辑资源与存储资源开销。&lt;/p&gt;

&lt;p&gt;(2) 构建通用可配置的向量处理引擎。由于改进的 YOLOv2 网络引入了空洞卷积、转置卷积等多种类型的卷积运算，增大了部署在 FPGA 上的难度。因此我 们凝练多种卷积运算类型的共同处理特点，提出了一种可配置的向量处理引擎。 该引擎可以在 FPGA 上实现多类型卷积运算，节省了资源，且极大提高了设计的灵活性。&lt;/p&gt;

&lt;p&gt;(3) 构建适用于神经网络的并行处理策略。本设计挖掘神经网络中卷积运算的并行运算潜力，合理利用 FPGA 上的运算资源，搭建运算流水线结构，实现卷积神经网络前向推断的高效处理。提高了处理性能。&lt;/p&gt;

&lt;p&gt;(4) 搭建了基于 FPGA 的低功耗遥感图像处理系统。与传统的卷积神经网络的实现平台 GPU 相比，该作品的功耗要低一个数量级。同时，在 DOTA 遥感数据集上的测试表明，本作品的检测性能与 GPU 一致。因此本作品在功耗和处理速度之间取得折衷，在功耗受限的特定应用场景中部署更具优势。&lt;/p&gt;

&lt;h1 id=&quot;第二部分-系统组成及功能说明&quot;&gt;第二部分 系统组成及功能说明&lt;/h1&gt;

&lt;p&gt;2.1 算法介绍&lt;/p&gt;

&lt;p&gt;2.1.1 改进的 YOLOv2 网络结构&lt;/p&gt;

&lt;p&gt;近年来，多种基于卷积神经网络的方法被提出，例如 R-CNN[4]、SSD[5]和 YOLO[6] 等，都被广泛用于深度学习领域的目标检测。与其他方法相比，YOLO 确保了准确性和速度之间的极佳折衷。在本作品中，我们选用了一种改进的 YOLOv2 网络用于遥感物体检测。该网络采用了扩展卷积和转置卷积，从而提高了复杂光学遥感场景中 多尺度物体的性能。该网络在模型复杂度和对象检测性能之间进行了权衡。其网络 结构如图 2 所示，其中，基础工作包含多个计算层，它们相互连接在一起。主要层 是卷积层，池化层，批量归一化层和激活函数。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/remote_sensing/improved_YOLOv2.png&quot; alt=&quot;improved_YOLOv2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;2.1.2 面向 FPGA 的量化策略&lt;/p&gt;

&lt;p&gt;目前，多数的卷积神经网络训练后的网络模型为浮点类型。若采用该方式进行前向推断，所有运算操作均为浮点类型，会给 FPGA 实现带来巨大的存储和计算压力。&lt;/p&gt;

&lt;p&gt;针对上述问题，我们采用了基于量化算法的深度神经网络混合精度计算方法， 利用低位宽的数据类型进行数据表达与计算，从而有效优化硬件结构设计。量化算法可看作对卷积神经网络模型进行近似线性变换，在不改变卷积神经网络的运算类型与运算结构的前提下，将全浮点的网络参数全部转化为适合 FPGA 实现的整数型， 以此降低硬件加速器的复杂度；同时保持一定的浮点精度计算，支撑遥感图像智能处理的海量计算需求。量化过程的示意图如图 3 所示。但是上述方法在训练阶段难以直接实现，这是由于整型表达导致了网络不可导。此外，混合精度计算带来一定的误差，影响网络处理性能。针对上述问题，我们采用了模拟硬件处理的量化神经网络训练方法，有效保证低位宽数据表达网络的正常训练，采用为了有效抑制量化推断带来的误差。在前向推断阶段，应用上述方法设计混合精度处理引擎，相比于浮点计算引擎，能够大幅降低计算引擎所需资源。在有限的逻辑资源条件下，所能集成的引擎集成度大幅调高，系统处理能力及效率也随之提高。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/remote_sensing/Quantization.png&quot; alt=&quot;Quantization&quot; /&gt;&lt;/p&gt;

&lt;p&gt;2.1.3 卷积神经网络基本功能层&lt;/p&gt;

&lt;p&gt;1、卷积层&lt;/p&gt;

&lt;p&gt;卷积层是卷积神经网络的核心处理，一个二维卷积的操作如图 4 所示。一个 卷积层的内部包含多个卷积核，每个卷积核的所有元素都对应一个参数，每个卷 积核对应一个偏置。我们用 y 来表示图像卷积后的输出，用 i 和 j 来表示输出图 像的行和列，用 x 表示输入图像，用 w 表示卷积核的参数，用ｍ和ｎ来表示卷 积核的行和列，M 和 N 表示卷积核的长和宽，则卷积的过程遵循公式 1：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/remote_sensing/formula1.png&quot; alt=&quot;formula1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;卷积示意图如图 4 所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/remote_sensing/conv.png&quot; alt=&quot;conv&quot; /&gt;&lt;/p&gt;

&lt;p&gt;卷积运算是一种具有多层次循环的乘累加运算。在神经网络中卷积运算涉及的数据量很大，FPGA 的运算单元有限，往往不能并行处理全部的输入数据；同时 FPGA 片上存储资源也是有限的，卷积运算的大量原始图像、参数与中间结果也不能完全存在片上，因此需要将运算数据分块处理。数据切分往往涉及多个维 度，并且当原始数据被分块时，处理时会产生多个中间结果，中间结果可通过叠加得到最终结果。&lt;/p&gt;

&lt;p&gt;2、批次规范化层&lt;/p&gt;

&lt;p&gt;目前多数卷积神经网络会在卷积层后插入批次规范化层，其的定义如公式 2 所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/remote_sensing/formula2.png&quot; alt=&quot;formula2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其中，μ 和 σ 表示输入特征图的均值和标准差估计值。γ 和 β 是批归一化层的学习参数。从公式上看批次规范化层可分为两部分，第一部分是输入的规范化； 第二部分是在此基础上进行线性变换。从运算类型上来看，批次规范化层属于像素级乘加运算。&lt;/p&gt;

&lt;p&gt;3、激活函数&lt;/p&gt;

&lt;p&gt;卷积神经网络中每个神经元节点都是接收上一层网络的输出值作为本层网络的输入值，并将本层网络的操作结果传递给下一层。在多层的卷积神经网络之中，上一层的输出值与下一层的输入值之间会插入激活函数，如图 5 所示。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/remote_sensing/expansion.png&quot; alt=&quot;expansion&quot; /&gt;&lt;/p&gt;

&lt;p&gt;常用的激活函数 ReLU 函数如公式 3 所示，图 6 为 ReLU 激活函数示意图。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/remote_sensing/Relu.png&quot; alt=&quot;Relu&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ReLU 函数的本质是与 0 做比较，大于 0 的数字保持不变，小于零的数值激活为 0，计算过程简单易于实现。但是 ReLU 函数也存在一定的问题，对于负数 输入可能会导致梯度弥散，因此也有网络采用 LeakyReLU 作为激活或函数。 LeakyReLU 是原始 ReLU 的一个变体，如公式 4 所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/remote_sensing/leakyRelu.png&quot; alt=&quot;leakyRelu&quot; /&gt;&lt;/p&gt;

&lt;p&gt;4、池化层&lt;/p&gt;

&lt;p&gt;池化操作分为最大值池化与均值池化。在卷积神经网络中，卷积层后面往往跟着一个池化层。在卷积层提取完特征之后，会有一个池化层来对输入特征图像的信息进行过滤，并且进行特征选择。&lt;/p&gt;

&lt;p&gt;池化计算层的使用是模仿人类大脑提取信息时的降维和抽象的过程。它主要有三个作用：&lt;/p&gt;

&lt;p&gt;1）池化采样使网络模型降低了对特征位置的敏感程度，容许特征学习过程中一些特征位置细微改变的存在，让网络在处理图像扭曲方面的能力得到增强；&lt;/p&gt;

&lt;p&gt;2）池化层又称降采样层，它降低了特征映射图的维度，同时减小了下一层 计算输入的数据规模，进而减小计算量和参数个数，这对于硬件实现是非常有利的；&lt;/p&gt;

&lt;p&gt;3）池化层在一定程度上能够降低数据过拟合的风险。 池化操作主要是将单个点的结果替换为某个区域的特征统计量。均值池化在相邻的 2×2 的区域内，将四个数求和再求平均值，得到输出结果，用四个像素点 的平均值来代替这一区域的像素值；最大值池在相邻 2×2 区域内的最大值来代替这一区域的像素值，如图 7 所示。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/remote_sensing/expanation2.png&quot; alt=&quot;expanation2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;2.2 整体系统介绍&lt;/p&gt;

&lt;p&gt;神经网络算法处理过程均具备可并行度高、可复用度高、处理数据量大、处理流程复杂的特点，可归类为数据流驱动的运算密集型处理过程。为了满足以上处理特点，需要设计大规模的处理阵列进行并行处理，为满足这一条件本方案采用 Xilinx VC709 板卡作为实现平台。Xilinx VC709 板卡上核心 FPGA 为 XC7V690T，配备独立双通道 DDR3（512bit@200MHz）。基于该平台，本方案设计了神经网络硬件加速系统架构，如图 8 所示。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/remote_sensing/achitecture.png&quot; alt=&quot;achitecture&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们所提出的神经网络硬件加速系统架构主要包括 3 个子系统：&lt;/p&gt;

&lt;p&gt;1、处理引擎子系统&lt;/p&gt;

&lt;p&gt;该子系统负责神经网络具体算法的实施，主要完成计算处理的任务。神经网 络处理引擎阵列由 32 个处理引擎组成，每个处理引擎由 32 个乘累加器构成，进行高并行向量乘加运算。&lt;/p&gt;

&lt;p&gt;除引擎阵列外，该子系统配有相应的输入与输出控制，输入控制负责从输入存储子系统获取原始数据；输出控制负责实现中间结果与最终结果的存储路由。 处理引擎子系统的所有控制需要与主状态机进行交互。&lt;/p&gt;

&lt;p&gt;2、存储子系统&lt;/p&gt;

&lt;p&gt;存储子系统实现对内外部的存储模块进行管理，可分为存储器单元以及存储路由控制。&lt;/p&gt;

&lt;p&gt;存储器单元：用于实现数据缓冲，分为外部存储器和内部存储器。外部存储器采用 2 片容量大、顺序访问速度快的 DDR 芯片，用于保存原始数据与模型参数，数据缓冲周期长的数据保存在其中，内部存储器采用访问速度快、位宽大、 功耗低、容量小、可随机访问的 BRAM，用于缓存部分数据及数据运算中间结果，数据缓冲周期短的数据保存在其中。为保证不同图像处理引擎访问存储器单元时不发生数据堵塞，将存储空间划分成不同容量的独立子存储单元。内部缓存包括：输入特征图缓冲区、参数缓冲区、输出特征图缓冲区以及中间结果缓冲区。&lt;/p&gt;

&lt;p&gt;存储路由控制：每个子存储单元通过输入/输出接口与存储仲裁单元相连，处理引擎也通过数据访问接口与存储仲裁单元相连，可实现多通道引擎和存储器之间的访问映射。内部存储器与处理引擎阵列子系统间的内存访问映射由主状态进行配置。&lt;/p&gt;

&lt;p&gt;3、指令处理子系统&lt;/p&gt;

&lt;p&gt;指令处理子系统又指令队列、指令解码器、主状态机构成。指令队列从外部接收指令需要处理的指令并储存，所有指令顺序排列，先入先出。指令解码器负责从指令队列中取出指令，进行指令解析并传输给主状态机。主状态机将存储访问指令传输至存储子系统，用于配置该条指令的数据读/写通路；将处理指令传输至处理引擎子系统，用于选择处理算法引擎与配置引擎参数。主状态在算法处理过程中与存储子系统和处理引擎子系统均进行交互，以实现流程控制。当指令队列中所有指令全部处理完成后，从外部继续接受下一批处理指令，直至指令全部处理完成。&lt;/p&gt;

&lt;p&gt;2.3 各模块介绍&lt;/p&gt;

&lt;p&gt;2.3.1 指令处理子系统&lt;/p&gt;

&lt;p&gt;接收解析后的指令，对各个模块进行配置。主状态机将存储访问指令传输至存储子系统，用于配置该条指令的数据读/写通路；将处理指令传输至处理引擎子系统，用于选择处理算法引擎与配置引擎参数。主状态在算法处理过程中与存储子系统和处理引擎子系统均进行交互，以实现流程控制。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/remote_sensing/processing.png&quot; alt=&quot;processing&quot; /&gt;&lt;/p&gt;

&lt;p&gt;如图 9 所示，主状态机由状态切换模块和状态输出模块组成。用于配置信息和模块间的握手。&lt;/p&gt;

&lt;p&gt;2.3.2 处理引擎子系统&lt;/p&gt;

&lt;p&gt;该模块包含三个功能，分别是卷积运算、批量标准化(BN)融合层运算、激活 融合层运算。本设计方案中的运算模块最多可对 32 个输入通道的数据进行乘累 加运算，并将 32 个输出通道的结果并行输出。&lt;/p&gt;

&lt;p&gt;为了令我们的处理引擎子系统可以适用于多种卷积类型在 FPGA 上的实现， 我们对卷积运算进行了分析和改进。以常规卷积层为例，以单张图计算 （BatchSize=1），其输入特张图张量为三维张量 Tensor(Nif, NH, NW)，权重参数 为四维度张量 Tensor(Nof, Nif, Nkh, Nkw)，输出特征图为三维张量 Tensor(Nof, NH, NW)。其中 Nif、NH、NW为分别表示输入特征图张量的输入通道数、高、宽；Nkh、 Nkw为卷积核的高、宽；Nof为输出特征图张量的输出通道数其计算公式&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/remote_sensing/con_formula.png&quot; alt=&quot;con_formula&quot; /&gt;&lt;/p&gt;

&lt;p&gt;卷积运算可看为两部分，上三层循环为输出结果索引不参与叠加过程，下三 层循环为卷积计算核心部分。下三层循环计算可看作图 12 中绿色立方体与紫色立方体的对应点乘法后再求和。目前已有的工程中我们按照上述循环展开方式进行设计，首先计算二维卷积核内部计算，而后通过循环叠加将所有输入通道进行 组合。但是这种方案在支持多种卷积运算时需要进行数据读取重排序，在硬件实现时数据流控制较难。此外，卷积运算是一种具有多层次循环的乘累加运算。在神经网络中卷积运算涉及的数据量很大，FPGA 的运算单元有限，往往不能并行处理全部的输入数据；同时 FPGA 片上存储资源也是有限的，卷积运算的大量原始图像、参数与中间结果也不能完全存在片上，因此需要将运算数据分块处理。 数据切分往往涉及多个维度，并且当原始数据被分块时，处理时会产生多个中间结果，中间结果可通过叠加得到最终结果。&lt;/p&gt;

&lt;p&gt;针对上述问题，本方案采用了循环变换。对图 10 中公式进行循环变换，将 Loop{1, 2, 3, 4}的顺序变换为 Loop{2, 3, 1, 4}，循环变换后的卷积运算公式如图 11 所示。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/remote_sensing/con_formula2.png&quot; alt=&quot;con_formula2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从上述公式可以看出，经过循环变换后的卷积计算在运算类型和运算数量上没有任何变化，只改变了循环叠加顺序。根据上述公式进行卷积运算可以分解为两个步骤：&lt;/p&gt;

&lt;p&gt;1、特征图均按照输入通道维度进行数据采样，采样的数据构成特征图向量， 其维度为(1, Nif,)。卷积核采用按输出通道进行同位置独立采样（第一次运算时为所有输出通道卷积核第一行第一个点的所有输入通道数据），采样后的数据构成二维矩阵，其维度为(Nif, Nof)。采用后的特征图向量与卷积核矩阵进行向量乘矩阵运算，即可得到特征图结果向量，其维度为(1, Nof)，这些结果对应输出特征图第一行第一个点的所有通道数据。该过程如图 12 所示。&lt;/p&gt;

&lt;p&gt;2、向右向下（向右至行尾后，从第二行第一个点开始）依次取特征图向量， 此过程可以看作是步骤 1 中采样位置在特征图张量上的向右向下依次滑动。保持步骤 1 中的卷积核矩阵不变，重复步骤 1 即可获得所有输出特征图中间结果，其 过程如图 12 所示。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/remote_sensing/con_formula3.png&quot; alt=&quot;con_formula3&quot; /&gt;&lt;/p&gt;

&lt;p&gt;3、向右向下依次卷积核向量构成卷积核矩阵，重复步骤 1、2，获得第二组中间结果，这些中间结果与步骤 2 中所有结果进行对应位置相加，最终获得所有输出结果。应用此方法能够突破原有方案中卷积核尺寸限制以及卷积类型的限制，通过循环叠加次数来实现不同尺寸卷积运算。&lt;/p&gt;

&lt;p&gt;卷积运算模块主要由卷积输入控制模块、卷积输出控制模块、卷积计算阵列模块和卷积状态控制、BN 输入控制模块、BN 融合模块、激活融合模块组成。图 13 为卷积运算模块的结构框图&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/remote_sensing/enginee_achitecture.png&quot; alt=&quot;enginee_achitecture&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其中卷积计算阵列模块包含 32 个计算单元（PE），每一个 PE 能一次完成 32 个数的乘累加运算。整个系统设计中包含 32 个并行排列的 PE。每个 PE 内部由 32 个乘累加器组成，接收输入特征图、卷积核及中间结果。如图 14 所示，每 个 PE 内部的 32 个 MAC 相互级联，主要针对常规的卷积运算。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/remote_sensing/32_mac.png&quot; alt=&quot;32_mac&quot; /&gt;&lt;/p&gt;

&lt;p&gt;BN 运算模块中包含 32 个 BN 处理单元，可以同时计算 32 个点的批量标准化及反量化运算，分别对应 32 个计算通道。每个计算单元中主要执行 3 步运算。 定点转浮点、浮点乘法、浮点加法。如图 15 所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/remote_sensing/BN.png&quot; alt=&quot;BN&quot; /&gt;&lt;/p&gt;

&lt;p&gt;激活运算模块中包含 32 个激活处理单元，可以同时计算 32 个点的激活及量化运算。本层的两个参数存储在片上的两块 ROM 中，在换层时会提前被读出， 通过判断当前点的正负来参与运算。此外，本模块还会进行一个定点转浮点的运算。从而得到了 8bit 定点的输出结果。如图 16 所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/remote_sensing/LeakyReLU_unit.png&quot; alt=&quot;LeakyReLU_unit&quot; /&gt;&lt;/p&gt;

&lt;p&gt;2.3.3 输入特征图缓存模块&lt;/p&gt;

&lt;p&gt;输入特征图缓存模块的功能是暂存来自 DDR 控制器发送的输入特征图数据，并对运算模块发出的读请求进行响应，按照所需的数据顺序进行读出。&lt;/p&gt;

&lt;p&gt;输入特征图缓存模块由写控制、读控制、请求处理控制、片上存储体组成， 如图 17 所示。其中，存储体是一块数据位宽为 256 的 BRAM 构成。大小为 1MB&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/remote_sensing/buffer.png&quot; alt=&quot;buffer&quot; /&gt;&lt;/p&gt;

&lt;p&gt;2.3.4 卷积核缓冲模块&lt;/p&gt;

&lt;p&gt;卷积核缓存模块的功能是对卷积核数据进行缓存，并处理来着卷积运算模块的读请求，将数据按特定的顺序反复读出。该缓存模块能够同时存储 32 个输出通道的卷积核。&lt;/p&gt;

&lt;p&gt;卷积核缓存模块由写控制、读控制、请求处理控制、片上存储体组成，如图 18 所示。其中，存储体是 32 块数据位宽为 256 的 BRAM 构成，大小为 1MB。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/remote_sensing/buffer1.png&quot; alt=&quot;buffer1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;2.3.5 中间缓存模块&lt;/p&gt;

&lt;p&gt;中间缓存模块的功能是对卷积运算模块输出的中间结果进行缓冲，当卷积运算完成时，为卷积后续的 BN 模块提供数据。&lt;/p&gt;

&lt;p&gt;如图 19 所示，中间缓存模块由读控制、写控制以及 FIFO 存储阵列组成，其中 FIFOs 由 32 个端口位宽位 32 的 FIFO 组成。总大小为 1024&lt;em&gt;32&lt;/em&gt;32b。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/remote_sensing/buffer2.png&quot; alt=&quot;buffer2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;2.3.6 输出缓存模块&lt;/p&gt;

&lt;p&gt;输出缓存模块用于存储经过 BN，融合等操作的计算结果。当存储的数据达到预设值时，向 DDR 发送数据，该缓冲区大小为 1MB。&lt;/p&gt;

&lt;p&gt;输出缓存模块由参数配置、读控制、写控制、交互控制和存储体组成，如图 20 所示。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/remote_sensing/buffer3.png&quot; alt=&quot;buffer3&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;第三部分-完成情况及性能参数&quot;&gt;第三部分 完成情况及性能参数&lt;/h1&gt;

&lt;p&gt;3.1 测试平台搭建&lt;/p&gt;

&lt;p&gt;本作品在 Xilinx VC709 板卡上实现了改进版 YOLOv2 目标检测算法。硬件 部分已完成了指令处理子系统、处理引擎子系统以及存储子系统。其中，处理引擎子系统包含了普通、转置、空洞卷积，以及池化、激活等操作，满足本设计所采用的改进版 YOLOv2 的运算需求。&lt;/p&gt;

&lt;p&gt;本作品的具体测试平台包括上位机演示系统、Xilinx Zedboard 板卡以及 Xilinx VC709 板卡。 其中，Zedboard 板卡和 VC709 板卡通过 FMC 连接器交互， 如图 21 所示。本作品具体运行流程如下：&lt;/p&gt;

&lt;p&gt;1、上位机演示系统负责前端界面的显示，并完成待检测图片的加载、回传结果的后处理及展示。待检测图片和回传结果经由网线传输。&lt;/p&gt;

&lt;p&gt;2、Zedboard 板卡负责 Linux 操作系统及驱动的加载，并接收上位机传送的待测图片，并将待测图片、YOLOv2 配置指令和相关参数经由 FMC 连接器送与 VC709 板卡处理，检测结果通过 FMC 连接器返回，并发往上位机。&lt;/p&gt;

&lt;p&gt;3、VC709 板卡完成了指令处理子系统、处理引擎子系统以及存储子系统的实现，该板卡根据卷积神经网络的配置指令和参数，对待测图像进行检测，并通 过 FMC 连接器将检测结果返回给 Zedboard。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/remote_sensing/test_plat.png&quot; alt=&quot;test_plat&quot; /&gt;&lt;/p&gt;

&lt;p&gt;3.2 软硬件环境介绍&lt;/p&gt;

&lt;p&gt;1、FPGA 板卡:Xilinx Zedboard 和 Xilinx VC709&lt;/p&gt;

&lt;p&gt;2、数据传输:双绞线、FMC 连接器&lt;/p&gt;

&lt;p&gt;3、设计软件:Xilinx Vivado 2019.2&lt;/p&gt;

&lt;p&gt;4、用于对网络结果进行后处理及界面显示的上位机&lt;/p&gt;

&lt;p&gt;3.3 性能指标&lt;/p&gt;

&lt;p&gt;1、准确性：利用 GPU 平台改进的 YOLOv2 网络在 DOTA 遥感数据集上测试，mAP 指标可以达到 69.0。我们在 FPGA 上所实现的该深度卷积神经网络的测试结果与 GPU 平台运行结果一致，保证了作品的准确性。&lt;/p&gt;

&lt;p&gt;2、运行效率：基于改进的 YOLOv2 网络，对单张尺寸为 1024x1024 的图像进行多目标检测的处理时间为 0.9248 秒。若加上数据传输、结果后处理以及图像显示等过程，单张图像的处理及展示时间约为 1.5 秒。（在视频展示时，多张 图测试过程中，由于作品的处理速度快于每张图所展示的时长，所以可以看到原图和检测结果几乎同时显示。）&lt;/p&gt;

&lt;p&gt;3、功耗：本作品在 200M 的时钟频率下，总功耗为 16W，单位功耗处理能力为 25GOPs/W。与 GPU 平台相比，具有更低的功耗和更优的能耗比。因此本作品更适合部署在对实现平台的体积、重量、功耗有限制的应用环境中。&lt;/p&gt;

&lt;p&gt;3.4 FPGA 资源利用率&lt;/p&gt;

&lt;p&gt;本作品 FPGA 资源占用情况如表 1 所示，其中 DSP 占用了 65.78％，BRAM 占用了 54.01％，资源使用情况合理。该硬件平台能够有效部署 YOLOv2 目标检测网络，实现多尺度、多类型目标的高精度快速检测及分类。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/remote_sensing/resource_utilize.png&quot; alt=&quot;resource_utilize&quot; /&gt;&lt;/p&gt;

&lt;p&gt;3.5 结果演示&lt;/p&gt;

&lt;p&gt;本作品基于改进的 YOLOv2 网络，在实现飞机、车辆等多目标的检测的同时， 可实现多检测目标的分类，其上位机界面显示结果如图 23 所示。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/remote_sensing/Qt.png&quot; alt=&quot;Qt&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;第四部分-总结&quot;&gt;第四部分 总结&lt;/h1&gt;

&lt;p&gt;4.1 可扩展之处&lt;/p&gt;

&lt;p&gt;（1）目前卷积神经网络的部署仍采用人工方式生成对应的指令代码，未来可结合软件编译工具，是指令代码生成自动化，从而达到多种网络的动态部署和资源的动态分配。&lt;/p&gt;

&lt;p&gt;（2）目前该作品暂不支持深度可分离卷积、分组卷积和 Shortcut 等运算方式，未来可在处理引擎子系统上进行扩展，进一步提高该作品的通用性。&lt;/p&gt;

&lt;p&gt;（3）目前我们在 FPGA 上实现了深度卷积神经网络。但 FPGA 作为一种通用处理器，其处理性能和功耗控制都存在瓶颈。因此后续我们会以本作品为基础， 设计与开发用于遥感图像在轨实时处理的 ASIC 芯片。&lt;/p&gt;</content><author><name>XUP-2020</name></author><category term="2020competition" /><category term="project" /><summary type="html">作者：张宁 李铿 曹云飞</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="/OpenHW/assets/images/remote_sensing/cover.jpg" /><media:content medium="image" url="/OpenHW/assets/images/remote_sensing/cover.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">基于 ZYNQ 的激光雷达三维建模</title><link href="/OpenHW/zynq_Lidar/" rel="alternate" type="text/html" title="基于 ZYNQ 的激光雷达三维建模" /><published>2019-01-25T00:00:00+08:00</published><updated>2019-01-25T00:00:00+08:00</updated><id>/OpenHW/zynq_Lidar</id><content type="html" xml:base="/OpenHW/zynq_Lidar/">&lt;p&gt;作者；岳恒；李志远；史巧雅&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/all_white.jpg&quot; alt=&quot;isolution&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;第一部分-设计概述&quot;&gt;第一部分 设计概述&lt;/h1&gt;

&lt;p&gt;1.1 设计目的&lt;/p&gt;

&lt;p&gt;近年来，机器学习，无人驾驶等领域是十分热门的研究话题。在这些领域中，电脑对环境的感知十分重要。因此三维的环境重建是必然的趋势，方便我们实现虚拟世界与现实世界之间的交互。&lt;/p&gt;

&lt;p&gt;在三维重建中，主流的方式有视觉和激光雷达两种。视觉技术的测距方法是基于三角的测距法，最大范围是 5-8m，并不适用于较大的空间，且这种方法受光线的影响很大。相比之下，激光雷达可以用于的场景更为广泛。&lt;/p&gt;

&lt;p&gt;1.2 应用领域&lt;/p&gt;

&lt;p&gt;三维建模的应用很广泛，例如无人机、无人驾驶汽车的即时避障，路径规划。同时也可以与机器视觉、3D 打印等技术也可以融合。在文物复刻和重建也是十分有意义的应用。 本次设计的基于 ZYNQ 的激光雷达三维建模系统，可以深入目标环境， 进行点云采集，重建三维空间模型，测量等机器视觉方面的应用。&lt;/p&gt;

&lt;p&gt;1.3 主要技术特点&lt;/p&gt;

&lt;p&gt;首先，本系统采用 pcl 点云库中的 icp 算法，可将激光雷达返回的数据进行多次迭代计算，实现精确配准。&lt;/p&gt;

&lt;p&gt;其次，本系统将激光雷达搭载在麦轮小车上，通过小车陀螺仪和电机编码器，实时传输小车的位置和速度信息，通过坐标系变换可得到激光雷达的实时精准定位。&lt;/p&gt;

&lt;p&gt;本设计可以对距离为 1~5m，盲区较少的室内物体进行实时的三维重建， 不易受光线的影响。激光雷达搭载在可远程控制的小车上，可以用于勘察人无法进入的环境。&lt;/p&gt;

&lt;p&gt;1.4 关键性能指标&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/zynq_Lidar/performance.png&quot; alt=&quot;performance&quot; /&gt;&lt;/p&gt;

&lt;p&gt;1.5 主要创新点&lt;/p&gt;

&lt;p&gt;（1） 可通过移动 app 对小车进行远程控制；&lt;/p&gt;

&lt;p&gt;（2） 算法基于 PCL 点云库；&lt;/p&gt;

&lt;p&gt;（3） 通过 Icp 算法可达到实时数据配准；&lt;/p&gt;

&lt;p&gt;（4） 利用 pynq 的 PL 模块对 icp 算法进行 HLS 加速。&lt;/p&gt;

&lt;h1 id=&quot;第二部分-系统组成及功能说明&quot;&gt;第二部分 系统组成及功能说明&lt;/h1&gt;

&lt;p&gt;2.1 整体介绍&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/zynq_Lidar/bri_achi.png&quot; alt=&quot;bri_achi&quot; /&gt;&lt;/p&gt;

&lt;p&gt;图 2.1.1 是整个系统的实现框图。系统由激光雷达、基于 STM32 的麦轮小车 和 Xilinx 公司 PYNQ-Z2 组成的。其中激光雷达通过网口将采集到的点云数据传给 PYNQ-Z2，麦轮小车上搭载了电机编码器、陀螺仪和蓝牙模块。转向和移动可有手机蓝牙程序控制。在运动过程中，将位移和姿态信息传递给 STM32 单片机，通过 UART 协议 STM32 将这些信息传递给 PYNQ-Z2，ZYNQ 根据位移和姿态信息计算出激光雷达的位移和姿态偏移。ZYNQ 根据姿态和位置信息的偏移将点云数据利用 ICP 算法拼接起来，拼接后用网口传出数据。&lt;/p&gt;

&lt;p&gt;在本设计中，我们采用小车搭载激光雷达进行移动扫描，采集左、右和顶三面的信息进行重构。&lt;/p&gt;

&lt;p&gt;2.2 各模块介绍&lt;/p&gt;

&lt;p&gt;2.2.1 R-Fans-16 激光雷达&lt;/p&gt;

&lt;p&gt;本系统中激光雷达采集采用的是 R-Fans-16 导航型雷达，它通过 16 线 360°扫描实现三维探测成像。基于高精度激光回波信号测量技术，R-Fans-16 具备测程远（探测能力最远达到 200m），测量精度高（测距精度优于 2cm），回波强度准确（目标反射回波强度达到 8 位）等技术特点，同时兼顾了俯仰方向的角度覆盖和角分辨率。运行激光雷达时，通过网口将实时点云数据传输给 PYNQ-Z2。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/zynq_Lidar/Lidar.png&quot; alt=&quot;Lidar&quot; /&gt;&lt;/p&gt;

&lt;p&gt;2.2.2 基于 STM32 的麦轮小车&lt;/p&gt;

&lt;p&gt;在这个麦轮小车上搭载了 STM32 单片机，本次实验中，利用了小车上的陀螺仪、编码器和蓝牙。小车上的陀螺仪和电机编码器通过 SPI 协议将数据传给 STM32 单片机，单片机通过计算得到小车的姿态和轮胎转速，然后利用 UART 协议，以 115200 的波特率将数据循环实时发送给 ZYNQ。小车的移动和转向利用蓝牙远程控制。&lt;/p&gt;

&lt;p&gt;2.2.3 坐标系转换&lt;/p&gt;

&lt;p&gt;本设计中采用的是 R-Fans-16 导航型雷达，它采集的数据是建立在自身的坐标系之中的，三维重建的本质是将激光雷达坐标系中的数据转换为大地绝对坐标系，即球坐标系转化为直角坐标系。&lt;/p&gt;

&lt;p&gt;球坐标系是一种利用球坐标（r,θ,φ）表示一个点 P 在三维空间的位置的三维正交坐标系。如图 2.2.1 所示，原点与点 P 之间的“径向距离”为 r，原点到点 P 的连线与正 z 轴之间的“极角”为 θ,原点到点 P 的连线在 xy 平面的投影线与 x 轴之间的“方位角”为 φ。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/zynq_Lidar/coordinate.png&quot; alt=&quot;coordinate&quot; /&gt;&lt;/p&gt;

&lt;p&gt;球坐标系与直角坐标系之间的公式转化如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/zynq_Lidar/formula1.png&quot; alt=&quot;formula1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在本设计中，以车启动时的坐标为绝对坐标系的坐标原点，此后在每圈激光雷达的数据期间，以激光雷达为坐标原点建立一个个子坐标系，并记录此刻激光雷达在初始绝对坐标系下的位移偏转量。&lt;/p&gt;

&lt;p&gt;xyz 三个坐标轴的方向与激光雷达坐标系的轴方向一致。借助电机的编码器， 可测得激光雷达的水平平面移动速度和方向，即可得知激光雷达坐标系与绝对坐标之间的平移量；通过陀螺仪，可测得激光雷达的姿态角，以得知激光雷达坐标系与绝对坐标系之间的旋转量。借助以上测得的两个数值以及球坐标系与直角坐标系之间的转换公式，即可将激光雷达坐标系中的点映射到大地绝对坐标系中。&lt;/p&gt;

&lt;p&gt;2.2.4 点云配准（ICP 算法）&lt;/p&gt;

&lt;p&gt;ICP 算法配准就是要将两个不同坐标系下的点集，利用它们的几何特性匹配起来。需要求解目标点集和参考点集之间的刚体变换矩阵和平移矩阵，利用刚体变换矩阵作用在目标点集，使两个点集尽可能重合。对于目标点集 P 和参考点集 Q 来说，转换公式为：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/zynq_Lidar/formula2.png&quot; alt=&quot;formula2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上式不总是成立的，因此我们要最小化目标函数&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/zynq_Lidar/formula3.png&quot; alt=&quot;formula3&quot; /&gt;&lt;/p&gt;

&lt;p&gt;求解 R 和 T 常用的方法有：SVD 和非线性优化。本设计中使用了 SVD 的方 法。&lt;/p&gt;

&lt;p&gt;ICP 算法问题通常转换为最小二乘最优解问题，将整个问题分为两部分，第一部分是第二部分的基础和输入。第一部分称为粗略配准或全局配准，粗略配准即通过计算两点集间的位姿，得出点集间的大致重合结果，为下一步的精确配准提供合适初值。第二部分称精确配准或局部配准，对两个距离足够接近的点集使用迭代优化策略以达到最终的配准结果。&lt;/p&gt;

&lt;h1 id=&quot;第三部分-完成情况及性能参数&quot;&gt;第三部分 完成情况及性能参数&lt;/h1&gt;

&lt;p&gt;3.1 总述&lt;/p&gt;

&lt;p&gt;本系统本设计完成了激光雷达的点云采集、 陀螺仪、编码器的姿态信息采 集。 PYNQ-Z2 开发板的控制芯片 ZYNQ 使用的 PS-PL 设计极大地提高了系 统设计的便捷性、可行性，降低了系统的设计难度。 PS-PL 主从设计在保留系 统设计的简易性同时提高了系统的运行速度和处理能力。PL 端 IP 核的设计极 大地加快了算法的计算速度。本设计的点云拼接部分通过 PL 端的 IP 核加速， 增强了拼接效果，成功地实现了实时三维重建的功能。&lt;/p&gt;

&lt;p&gt;3.2 完成情况&lt;/p&gt;

&lt;p&gt;在室内走廊中，我们摆放了一排桌子、一个消防灭火器，两侧分别为墙壁和 窗户，具体场景如下图 3.2.1 所示。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/zynq_Lidar/environment1.png&quot; alt=&quot;environment1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;每采集 200 帧作为一组数据，存入 pcd 文件，得到每组数据生成的原始图像如图 3.2.2 所示，图像右侧为摆放桌子一侧，可看到明显桌面和桌脚的细节，左侧较低测为摆放的消防灭火器。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/zynq_Lidar/raw_model.png&quot; alt=&quot;raw_model&quot; /&gt;&lt;/p&gt;

&lt;p&gt;每相邻两组点云进行 icp 配准，得到完整的小车驶过走廊的三维模型如图 3.2.3 所示。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/zynq_Lidar/corridor_model.png&quot; alt=&quot;corridor_model&quot; /&gt;&lt;/p&gt;

&lt;p&gt;图片右侧离散的小点云为走廊中的窗户投射到室外返回的激光，若走廊两侧都为墙面，则可返回得到完&lt;/p&gt;

&lt;p&gt;3.3 性能参数&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/OpenHW/assets/images/zynq_Lidar/performance1.png&quot; alt=&quot;performance1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;激光雷达点云采集时距离越远分辨率越低，在有效探测距离内对物体的宽度和深度的测量误差取决于设备的稳定性（这里指激光雷达的抖动程度）。宽度测量误差在 2cm 内，倾斜物体的测量误差为 6cm，倾斜角度的误差为 4°。 由于测量时小车自身会有轻微抖动，所以结果有一定的误差。&lt;/p&gt;

&lt;h1 id=&quot;第四部分-总结&quot;&gt;第四部分 总结&lt;/h1&gt;

&lt;p&gt;4.1 可扩展之处&lt;/p&gt;

&lt;p&gt;（1）使用 python 编程。本次设计是 ZYNQ 上搭载了 Utunbu18.04，基于 C++ 语言的编程。使用过程中只能调用 C 语言基本的库中的函数以及 PCL 库函数， 显示并不方便，对使用者并不友好。可将 PCL 移植到 Jupyter 平台，利用 Python 更方便更快捷。&lt;/p&gt;

&lt;p&gt;（2）全方位的立体扫描。对于搭载激光雷达的小车来说，只能扫描小车的 左、右和顶三面进行单向的扫描。想要扫描一个特定的物体，则无法了解其立体的信息，可以选择更灵活的搭载物，例如无人机。&lt;/p&gt;</content><author><name>XUP-2020</name></author><category term="project" /><category term="competition" /><summary type="html">作者；岳恒；李志远；史巧雅</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="/OpenHW/assets/images/zynq_Lidar/cover.jpg" /><media:content medium="image" url="/OpenHW/assets/images/zynq_Lidar/cover.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>