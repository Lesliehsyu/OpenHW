I"F8<p>2019 年末，新冠疫情爆发, “保持人与人之间距离”的倡议也逐渐成为大家的共识。但事实上，在人流密集场合中，社交距离的保持时常被大家忽视。如何实时监测社交场合中人与人的距离，也成为一大难题。这也坚定了我们设计社交距离检测器的想法。</p>

<p>作者：王涵，潘捷，胡宇隆</p>

<p> </p>

<p><strong>第一部分 设计概述</strong></p>

<p> </p>

<p><strong>1.1 设计目的</strong></p>

<p>2019 年末，新冠疫情爆发, “保持人与人之间距离”的倡议也逐渐成为大家的共识。但事实上，在人流密集场合中，社交距离的保持时常被大家忽视。如何实时监测社交场合中人与人的距离，也成为一大难题。这也坚定了我们设计社交距离检测器的想法。</p>

<p>本作品名为社交距离检测装置。以 PYNQ-Z2 为控制核心，先对图像进行采集，后借助物体识别技术，进行多人对象的实时识别并输出到显示器。同时，我们结合距离检测算法，监测对象间的距离，并进行越限报警。</p>

<p><strong>1.2 应用领域</strong></p>

<p>本作品作为一款精度较高的距离检测器，具有广泛的应用场景。首先，在诸如商场、地铁站等公共人流密集场合中，本作品可以实时监测人与人之间的距离， 予以报警和监测，对于防止疫情具有重大意义。其次，在许多诸如篮球、足球的 运动竞技场合中，距离检测器也可以成为判罚的一大依据。除此以外，在银行 ATM 机排队取钱等场所，社交距离检测器的介入可以很好地保证取钱人的安全。 换句话来说，有距离检测需求的地方，就能有我们作品的身影。</p>

<p><strong>1.3 主要技术特点</strong></p>

<p>(1) 图像数据采集由双目摄像头同时拍摄的 640<em>480 分辨率照片构成的一张 1280</em>480 分辨照片，读取到图像后再分割成左右两幅照片，以供神经网 络处理。</p>

<p>(2) 基于 YOLO V2 神经网络的识别算法，可以实现多人识别、实时识别。</p>

<p>(3) 完成 PL 端的神经网络加速器 IP 设计，实现对卷积、池化等运算的加速。</p>

<p>(4) 基于双目测距的距离检测算法，可以实现距离的实时监测并越限报警。</p>

<p>(5) 采用双线程并行执行技术，将图像采集设置为一个线程，与数据处理的线程并行进行，两个线程通过队列进行数据传递，以提升处理器的利用率并降低延迟。</p>

<p><strong>1.4 关键性能指标</strong></p>

<p>(1) 该装置可以实现对画面中所有人物进行识别，由于采用YOLO神经网络， 并基于 COCO 数据集训练，识别精度较高，准确率可以接近 80%；</p>

<p>(2) 该装置在 5m 范围内能较好测量目标到摄像头的距离，且运算速度较快， 可以达到毫秒级, 如果时间允许，准备购置性能更优秀的摄像头，实现更高的精度；</p>

<p>(3) 该装置可以实现对画面中所有人进行三维空间中的距离测算，适用于多人场合；</p>

<p>(4) 该装置拥有极低能耗，峰值功率不超过 5W（不包括显示器），理论片上功率仅为 3.198W。</p>

<p><strong>1.5 主要创新点</strong></p>

<p>(1) 距离检测算法：本作品创新性的提出了基于双目成像的距离检测算法，并根据设置的阈值实时对图像中对象的距离进行报警；</p>

<p>(2) YOLO V2 神经网络加速：本作品利用 FPGA 上部署的硬件加速器对 YOLO V2 神经网络进行加速，提高了作品的快速性；</p>

<p>(3) 应用场合：本作品很好地适应了新冠疫情防护对社会公共卫生安全距离的要求，弥补了市场技术空白。</p>

<p> </p>

<p><strong>第二部分 系统组成及功能说明</strong></p>

<p> </p>

<p><strong>2.1 整体介绍</strong></p>

<p>本系统主要有双目摄像头模块、显示模块和主处理器三大模块构成，其中， 双目摄像头向系统输入图像信号，主处理器对双目摄像头输入的图像信号进行对应的识别处理，最后，显示模块将处理结果进行展示。</p>

<p><img src="/OpenHW/assets/images/article_4/image_1.png" alt="image_1" /></p>

<p><strong>2.2 各模块介绍</strong></p>

<p>2.2.1 双目摄像头模块</p>

<p><img src="/OpenHW/assets/images/article_4/image_2.png" alt="image_2" /></p>

<p>本系统的摄像头模块采用双目摄像头模组，100 度无畸变双目镜头，双目分辨率最高为 2560<em>960，实际采用 1280</em>480 分辨率，在 3m 以内具有良好的测距精度，输入帧率不低于三十帧，价格低廉，性能较稳定，符合本系统实用设计。 摄像头与 PYNQ 通过 USB 接口连接到 PS 端，免驱动，简洁方便。</p>

<p>该模块可以实现对图像的准确获取，并将图像首先输出到 PYNQ 的 PS 端进行深度图计算，并传入神经网络，借助 PL 端部署的神经网络加速器运算进行人物检测。</p>

<p>2.2.2 显示模块</p>

<p><img src="/OpenHW/assets/images/article_4/image_3.png" alt="image_3" /></p>

<p>显示部分采用的是 22 寸 HDMI 显示器，画面清晰，显示细腻。通过 HDMI 线缆与 PYNQ 的 PL 端输出端口项链，由 PL 端部署的 Video 模块控制视频的输出，连接方便简单。</p>

<p>显示屏显示摄像头采集到的图像，以及对于人像识别及测距结果，同时，对于人像间距离过近的警告予以显示。</p>

<p>2.2.3 主处理器信息</p>

<p><img src="/OpenHW/assets/images/article_4/image_4.png" alt="image_4" /></p>

<p>650MHz 双核 Cortex-A9 处理器，DDR3 内存控制器，带 8 个 DMA 通道 和 4 个高性能 AXI3 从端口。高带宽外设控制器：千兆以太网，USB 2.0，SDIO。 低带宽外设控制器：SPI，UART，CAN，I2C。可通过 JTAG，Quad-SPI 闪存 和 MicroSD 卡进行编程，可编程逻辑等效于 Artix-7 FPGA：13000 逻辑片，每个片有 4 个 6 输入 LUT 和 8 个触发器，630 KB 快速 Block RAM，4 个时钟管理片，每个片都有 一个锁相环（PLL）和混合模式时钟管理器（MMCM）， 220 个 DSP 片，片上模数转换器（XADC）。存储器：512MB DDR3，16 位总 线@1050Mbps，16MB 四 SPI 闪存，MicroSD 插槽。电源：由 USB 或 7V-15V 外部电源供电。</p>

<p> </p>

<p><strong>第三部分 完成情况及性能参数</strong></p>

<p> </p>

<p><strong>3.1 完成情况</strong></p>

<p><img src="/OpenHW/assets/images/article_4/image_5.png" alt="image_5" /></p>

<p>本系统由摄像头模块，显示模块，处理器模块共同构成。预计实现功能如下：</p>

<p>（1）通过人物识别，对画面中的人物对象进行识别；</p>

<p>（2）通过距离计算，输出人物对象与摄像头的距离于画面中；</p>

<p>（3）通过检测算法，计算人物对象间的距离，并与阈值进行比较和报警。(此处我们根据疫情期间政府对公共场合中对社交距离的要求，设置阈值为 1m)</p>

<p>目前，以上三大功能均已实现，各模块工作稳定，连接正常，除此以外，还需要进一步提升神经网络的运行速度。</p>

<p><strong>3.2 硬件设计</strong></p>

<p>3.2.1 硬件组成</p>

<p>系统的硬件组成如下图所示，首先，双目摄像头将视频信号输入到 PYNQ-Z2 板 ARM 上进行处理，再经由 Yolo 神经网络 IP 加速，最后由板上 Video IP 将处理结果的 HDMI 信号输出到显示器上予以展示。</p>

<p><img src="/OpenHW/assets/images/article_4/image_6.png" alt="image_6" /></p>

<p>3.2.2 FPGA 利用</p>

<p>PL 端主要加载了用于人物识别检测的神经网络加速器 IP 与用于 HDMI 输出的 Video IP。系统内部通过 AXI 总线连接。神经网络加速器通过四个 S_AXI_HP 端口与 PS 端连接，可以访问 DDR 内存上的数据；Video 模块通过 S_AXI_GP 端口与 PS 端相连，用于接收视频的 RGB 数据，然后转换成 DVI 信号通过 HDMI 口输出。</p>

<p><img src="/OpenHW/assets/images/article_4/image_7.png" alt="image_7" /></p>

<p>系统目前 LUT 占用 87%，DSP 占用 76%，BRAM 占用 70%，FF 占用 48%，充分地利用了片上资源。</p>

<p><img src="/OpenHW/assets/images/article_4/image_8.png" alt="image_8" /></p>

<p><strong>3.3 软件设计</strong></p>

<p>3.3.1 双目测距算法</p>

<p>双目测距原理大致如下：通过对两幅图像视差的计算，直接对前方景物 （图像所拍摄到的范围）进行距离测量，而无需判断前方出现的是什么类型的障碍物。所以对于任何类型的障碍物，都能根据距离信息的变化，进行必要的预警或制动。双目摄像头的原理与人眼相似。人眼能够感知物体的远近，是由于两只眼睛对同一个物体呈现的图像存在差异，也称“视差”。物体距离越远， 视差越小；反之，视差越大。视差的大小对应着物体与眼睛之间距离的远近， 这也是 3D 电影能够使人有立体层次感知的原因。其大体流程如下：</p>

<p><img src="/OpenHW/assets/images/article_4/image_9.png" alt="image_9" /></p>

<p>相较于单目测距算法，双目测距算法主要具有如下优势：</p>

<p>（1）成本比单目系统要高，但尚处于可接受范围内，并且与激光雷达等方案相比成本较低；</p>

<p>（2）没有识别率的限制，因为从原理上无需先进行识别再进行测算，而是对所有障碍物直接进行测量；</p>

<p>（3）直接利用视差计算距离，精度比单目高；</p>

<p>（4）无需维护样本数据库。</p>

<p>本作品通过 OpenCV 实现了 BM（Block-Matching）算法，其原理大致为将视频的当前帧划分为宏块，并将每个宏块与视频的附近帧中的相应块及其相邻邻居（有时只是前一个）进行比较。创建一个向量来模拟宏块从一个位置到另一个位置的运动。针对包括帧的所有宏块计算出的该运动构成了在帧中估计的运动。其优点在于算法速度较快，但精度略有损失。</p>

<p><img src="/OpenHW/assets/images/article_4/image_10.png" alt="image_10" /></p>

<p>3.3.2 YOLO V2 神经网络</p>

<p>YOLO 是典型的目标检测 one stage 方法，在 YOLO 算法中，核心思想就是 把物体检测（object detection）问题处理成回归问题，用一个卷积神经网络结构 就可以从输入图像直接预测 bounding box 和类别概率。用回归的方法去做目标检 测，执行速度快，达到非常高效的检测。</p>

<p><img src="/OpenHW/assets/images/article_4/image_11.png" alt="image_11" /></p>

<p>如上图所示，YOLOv1 的算法思想就是把一张图片，首先 reshape 成 448x448 大小（由于网络中使用了全连接层，所以图片的尺寸需固定大小输入到 CNN 中）， 然后将划分成 SxS 个单元格，以每个格子所在位置和对应内容为基础，来预测：</p>

<p>（1）检测框（2）每个框的 Confidence（3）每个格子预测一共 C 个类别的概率 分数。</p>

<p><img src="/OpenHW/assets/images/article_4/image_12.png" alt="image_12" /></p>

<p>网络方面采用 GoogLeNet，卷积层主要用来提取特征，全连接层主要用来预 测类别概率和坐标。并且，作者将其中的 Inception 模块换成了 1x1 卷积后接 3x3 卷积，最终网络结构由 24 个卷积层和 4 个最大池化层和 2 个全连接层组成。 </p>

<p>YOLO V2 相对初代有两方面主要改进：一，作者对原来的 YOLO 多目标检测框架进行了改进，在保持原有速度的优势之下，精度上得以提升。二，作者提出了一种目标分类与检测的联合训练方法，训练后的模型可以实现对最多达 9000 种物体的实时检测，我们的设备可以识别 80 种不同的物体，但仅筛选出所识别到的人用于检测。</p>

<p>3.3.3 软件总体设计</p>

<p>本装置软件部分主要包含 5 个方面，分别是：图像采集、距离计算、人物识别、距离判断、显示输出。</p>

<p><img src="/OpenHW/assets/images/article_4/image_13.png" alt="image_13" /></p>

<p>（1）图像采集：在 PS 端读取摄像头传入的同步双目图像数据，其是由两枚摄像头同时拍摄的 640<em>480 分辨率照片构成的一张 1280</em>480 分辨照片，读取到图像后再分割成左右两幅照片。并且，图像采集为单独的一个线程，与数据处理的线程并行进行，两个线程通过队列进行数据传递，以提升处理器的利用率并降 低延迟。</p>

<p>（2）距离计算：结合我们测量的摄像头标定参数，利用 OpenCV 库，使用 BM 算法对左右两幅图像进行匹配，以求得图像中各点的距离，并以左摄像头拍摄的图像为基准得到深度矩阵。这种算法速度快，虽牺牲了一定精度，但能降低延迟。</p>

<p>（3）人物识别：将左摄像头拍摄的画面处理后作为 YOLO 神经网络的输入， 并利用部署在 PL 端的神经网络加速器 IP 对卷积、池化等运算进行加速，得到网络输出的矩阵进行处理后再进行处理，筛选出图像中的人物以及其坐标和长宽。</p>

<p>（4）距离判断：结合 OpenCV 计算出的深度和 YOLO 神经网络计算出的人 物在图片中的坐标，得到人物在真实三维坐标中到摄像头的距离，并判断图像中所有识别出的人相互之间的距离，对所有没有保持社交距离的人做出标记。</p>

<p>（5）显示输出：在左摄像头的画面上用矩形标记处识别到的人物，并标出人 物距离摄像头的距离，单位为厘米。其中，与他人保持了良好社交距离的人用绿色的矩形框标出，没有与他人保持合适距离的人用红色的矩形标出，最后利用 PL 端的 Video 模块通过 HDMI 输出 640*480 分辨率的图像到显示器。</p>

<p> </p>

<p><strong>第四部分 总结</strong></p>

<p> </p>

<p><strong>4.1 可扩展之处</strong></p>

<p>（1） 改善人物识别的算法，进一步提高检测速度，降低延迟；</p>

<p>（2） 提高距离测量的精度，进一步提高检测报警的准确性；</p>

<p>（3） 提升硬件控制设备，进一步改善实时性。</p>
:ET