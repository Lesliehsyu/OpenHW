I"9<p>本设计针对低照度高动态情况下，单帧图像曝光不足导致的图像噪声大、色彩失准等问题，在传统的 HDR 多帧融合（Frames Merging）方法上，采用层次化的图像配准（Image Alignment）方案、自适应白平衡（White Balance）与色调映射（Tone Mapping）策略，在降低图像噪声、真实还原景物色彩的基础上，极大 抑制了多帧融合时常见的运动伪影（Motion Artifact）现象。本设计采用 FPGA 进 行图像处理加速后，可以实现视频流的实时处理，视频流经过摄像头输入后，由 FPGA 进行处理并以较低的时延经 HDMI 信号输出。</p>

<h1 id="基于多帧融合的智能相机处理系统">基于多帧融合的智能相机处理系统</h1>

<p>吴靖玮；姜雪涵；贺杨鹏</p>

<p> </p>

<p><strong>第一部分 设计概述</strong></p>

<p> </p>

<p><strong>1.1 设计目的</strong></p>

<p>本设计针对低照度高动态情况下，单帧图像曝光不足导致的图像噪声大、色彩失准等问题，在传统的 HDR 多帧融合（Frames Merging）方法上，采用层次化的图像配准（Image Alignment）方案、自适应白平衡（White Balance）与色调映射（Tone Mapping）策略，在降低图像噪声、真实还原景物色彩的基础上，极大 抑制了多帧融合时常见的运动伪影（Motion Artifact）现象。本设计采用 FPGA 进 行图像处理加速后，可以实现视频流的实时处理，视频流经过摄像头输入后，由 FPGA 进行处理并以较低的时延经 HDMI 信号输出。</p>

<p><strong>1.2 应用领域</strong></p>

<p>本设计可用于手持摄像系统（摄像机、智能手机）图像、视频流的 HDR 处 理，可用于低照度情况下固定监控系统的视频流 HDR 处理，可用于线上直播系统的视频流 HDR 处理。</p>

<p><strong>1.3 主要技术特点</strong></p>

<p>采用层次化的图像配准方案，对输入的拜尔格式（Bayer Mosaic）原始图像 进行处理，生成四层高斯图像金字塔（Gaussian Pyramids）。较高层次的图像配准结果将作为低层次配准的预偏移。这一过程极大优化了算法效率，其结构化的特 点为并行处理提供了便利。</p>

<p>采用有权重的图像融合方案，对输入的多帧图像，经图像配准后计算相应图像对（Image Pairs）的 L1 残差，得到各融合帧（Alternate Frame）相对参考帧 （Reference Frame）的权重，有效地降低了配准失误造成的运动伪影。</p>

<p>采用自适应白平衡及色调映射策略，在低光照情况下最大程度还原了景物的 色彩；在保证较高信噪比的情况下，提高了主要景物的亮度。</p>

<p>利用 FPGA 进行硬件加速，在 Pynq-z2 的 Python 开发环境中挂载封装有 IP 加速核的 Overlay，极大提高了运行速度，能够实时处理。</p>

<p><strong>1.4 关键性能指标</strong></p>

<p>相机感光度（ISO）、快门时间（Shutter Time）、融合帧数；</p>

<p>图像融合处理时间、视频流处理延时；</p>

<p>图像信噪比、色彩还原度、细节清晰度、纹理清晰度（人眼观察）。</p>

<p><strong>1.5 主要创新点</strong></p>

<p>（1） 低照度高动态图像处理；</p>

<p>（2） 层次化的图像配准；</p>

<p>（3） 有权重的图像融合降噪；</p>

<p>（4） 自适应白平衡与色调映射策略；</p>

<p>（5） FPGA 硬件加速；</p>

<p>（6） 低时延视频流处理。</p>

<p> </p>

<p><strong>第二部分 系统组成及功能说明</strong></p>

<p> </p>

<p><strong>2.1 整体介绍</strong></p>

<p><img src="/OpenHW/assets/images/article_8/image_1.png" alt="image_1" /></p>

<p>PYNQ-Z2 是基于 Xilinx ZYNQ-7000 FPGA 的平台，除继承了传统 ZYNQ 平 台的强大处理性能外，还兼容 Arduino 接口与标准树莓派接口，这使得 PYNQZ2 的具有极大的可拓展性与开源性。PYNQ 是一个新的开源框架，使嵌入式编 程人员能够在无需设计可编程逻辑电路的情况下即可充分发挥 Xilinx Zynq All Programmable SoC（APSoC）的功能。与常规方式不同的是，通过 PYNQ-Z2，用户可以使用 Python 进行 APSoC 编程，并且代码可直接在 PYNQ-Z2 上进行开发 和测试。通过 PYNQ-Z2，可编程逻辑电路将作为硬件库导入并通过其 API 进行编程，其方式与导入和编程软件库基本相同。</p>

<p>Xilinx Zyng All Programmable device 是一种基于双核 ARM cortex - a9 处理 器（称为处理系统或 PS）的 SOC，集成了 FPGA fabric(称为可编程逻辑或 PL)。 PS 子系统包括许多专用外设(内存控制器、USB、Uart、IIC、SPI 等)，并可以扩展额外的硬件 IP，其封装在 PL 的 Overlay 中。Overlay（或 Hardware Libraries， 硬件库）是可编程/可配置的 FPGA 设计，能将用户设计的应用从 Zynq 的处理系 统（PS 端）扩展到可编程逻辑（PL 端）。Overlay 可用于加速软件程序，或为特定程序定制硬件平台。</p>

<p><img src="/OpenHW/assets/images/article_8/image_2.png" alt="image_2" /></p>

<p>本设计的硬件平台整体结构如上图所示。为了对低照度高动态下的多帧融合 图像处理系统进行硬件加速，我们利用 Vivado HLs 工具，自主设计了 DownSample、Alignment、Merge、raw2rgb 等 IP Cores，并通过 AXI 总线与处理器核（PS 端）及存储器接口相连。在 PYNQ-Z2 的设计流中，这些 IP 被封装成 Overlay 并构造 Python API 驱动，以供 PYNQ-Z2 中的 Python 开发环境（JupyterNotebook）调用。</p>

<p>我们调用了 PYNQ-Z2 自有的 HDMI Overlay 进行处理流程及结果的显示。此外，PYNQ-Z2 为我们提供了丰富的存储单元、外设模块与通信接口。这些存储单元被用来存储图像数据及各类处理中间结果，而各类外设模块及通信接口则 被用来进行系统调试与控制的过程监控。</p>

<p><img src="/OpenHW/assets/images/article_8/image_3.png" alt="image_3" /></p>

<p>图像处理系统的工作流程如上图所示。相机在低曝光的情况下拍摄多帧（比 如说，6 帧）图片，这些原始图片（RAW images）由相机 CCD 或 CMOS 图像传感器生成，其像素值以拜耳阵列的形式存储。我们首先将原始各输入帧进行一次系数 2 的均值下采样，两次系数 4 的高斯下采样，得到一个四层的高斯图像金字塔。基于这个高斯图像金字塔，我们进行层次化的图像配准。配准的结果将作为图像融合的参考，同时结合备选帧与参考帧的 L1 残差作为融合权重，进行图像 融合。融合后的图像进行去马赛克及伽马降噪，并进行自适应的白平衡及色调映 射等操作，将单通道的融合图像转为三通道（对应 RGB 色彩空间）输出图像， 最终输出与原始图像同分辨率的处理结果。</p>

<p>均值下采样与高斯下采样处理被封装在名为 DownSample 的 IP core 中，层次化图像配准处理被封装在名为 Alignment 的 IP core 中，图像融合处理被封装在名为 Merge 的 IP core 中，去马赛克、白平衡、色调映射等处理被封装在名为 raw2rgb 的 IP core 中。这些 IP cores 挂载到 AXI 总线上，经封装为 Overlay 提供 Python API 给 PYNQ-Z2 的 Jupyter-Notebook。</p>

<p><strong>2.2 各模块介绍</strong></p>

<p>下采样模块（DownSample）</p>

<p>下采样模块为后续的层次化图像配准处理提供四层高斯图像金字塔。四层高斯金字塔的最底层为全分辨率的拜耳原始图像（我们称该层为 layer_raw），其像素点以拜耳阵列的形式排布，如下图所示。</p>

<p><img src="/OpenHW/assets/images/article_8/image_4.png" alt="image_4" /></p>

<p>我们首先进行系数 2 的均值下采样，直观上将一个 2*2 像素的“方格”取均值下采样为一个像素。下采样后的结果类似于一个单通道的灰度图像，但实际上绿色通道对下采样后的结果影响较大。我们称该层为 layer_0。</p>

<p>layer_0 随后进行两次系数 4 的高斯下采样。卷积核函数见附录。该卷积核 函数的大小为 5*5 像素，以 4 像素为步长在被采样的图像上以后，对该图像进行下采样。高斯下采样的结果将在一定程度上保留了采样前图像的低频信息，而图 像细节则被丢失。直观上图像的大致轮廓被保留，图像尺寸更小，细节模糊不清。 两次高斯下采样的结果分为称之为 layer_1 与 layer_2。</p>

<p>经下采样模块处理后的结果可以用下图说明。</p>

<p><img src="/OpenHW/assets/images/article_8/image_5.png" alt="image_5" /></p>

<p>图像配准模块（Alignment）</p>

<p>图像配准以图像对（Image Pairs）的形式，在融合备选帧（Alternate Frame） 与参考帧（Reference Frame）之间展开。对参考帧中的每一个 16*16 像素的图块 （Tile），寻找其在融合备选帧中使两者 L1 残差最小图块，两个图块位置上的偏 移即为配准结果。其 L1 残差的计算方式可用下式表达。</p>

<p><img src="/OpenHW/assets/images/article_8/image_6.png" alt="image_6" /></p>

<p>式中的求和对一个图块内的所有像素进行，配准的目的是对参考帧中的每一个图 块，寻找其在每一个备选帧中的对应图块，使得上式的结果最小。此时两个图块 的坐标偏移量即为配准结果。</p>

<p>在保证图像间偏差不大的前提下，图块配准的搜索范围可以限定图块原始位 置周围的若干像素内。为了进一步提高配准的效率，我们采用层次化的配准方案： 在上层低分辨率图像中进行预配准，配准结果将作为下层图像配准的预偏移 （Previous Offset）。各层图像以图块为基本单位，在预偏移的基础上进行小范围的配准。由此，上述残差计算式可以重新表达如下。</p>

<p><img src="/OpenHW/assets/images/article_8/image_7.png" alt="image_7" /></p>

<p>式中的𝑥<sub>𝑝</sub>, 𝑦<sub>𝑝</sub>即为上一层图像配准结果在本层配准的表达。</p>

<p>最终，层次化的图像配准处理将生成各层次上的配准结果。而我们所关心的 是全分辨率原始图像的配准结果，其将作为图像融合的依据进入到后续处理当中。</p>

<p><img src="/OpenHW/assets/images/article_8/image_8.png" alt="image_8" /></p>

<p>图像融合（Merge）</p>

<p>图像融合是多帧处理的关键步骤之一。在经过图像配准后，我们已经知道了参考帧中每一个图块在融合备选帧中的位置。这样一来，根据配准结果，从每一 个备选帧中提取相应的图块叠加在参考帧上，即可完成图像融合。然而，图像配准过程中有可能出现配准失误；另一方面，备选帧同样可能因为抖动而产生伪影。 这就需要依照参考帧图块与备选帧图块的偏差建立误差权重，误差小的图块融合时的权重大，而误差较大的图块在融合时的权重较小。</p>

<p>我们仍然使用类似于图像配准时的残差公式来计算误差，具体如下。</p>

<p><img src="/OpenHW/assets/images/article_8/image_9.png" alt="image_9" /></p>

<p>式中，𝑡<sub>𝑥</sub>,𝑡<sub>𝑦</sub>为参考帧中图块的索引，𝑥<sub>1</sub>, 𝑦<sub>1</sub>为配准后备选帧中图块内的像素 索引。通过计算相应图块内所有像素值的 L1 残差，我们就能衡量经过配准后的 图块对的误差，进而确定其在融合时的权重。</p>

<p>拜耳图像到 RGB 图像（raw2rgb）</p>

<p>上述处理的结果仍然是单通道的拜尔图像。我们需要将其转化为三通道的 RGB 图像，从而进行显示。余下的处理步骤通常包括校正（Correction）、去马赛 克（Demosaic）、色调映射（Tone Mapping）、白平衡（White Balance）等处理。 这些处理通常也由 ISP 完成。我们将这些处理封装在 raw2rgb 这一 IP core 中，进 而将处理的结果通过 HDMI 显示。</p>

<p> </p>

<p><strong>第三部分 完成情况及性能参数</strong></p>

<p> </p>

<p>我们完成了图 2 所述的各处理模块 IP cores 的封装与 Overlay 的挂载，通过在PYNQ-Z2本地读取一组6帧RAW格式拜耳图像（这些图像固定采用ISO=800， 快门时间为 1/16s 的拍摄参数），分块循环调用挂载的各处理模块 IP cores，进而 得到处理后的结果，通过 HDMI 进行显示。关键地，整个处理流程平均用时为83ms，并且具有进一步优化的空间。通过将更多的处理流程硬件化，减少在 AXI 总线上来回数据传输的次数，我们将进一步减少系统处理的平均用时。</p>

<p>下图是系统调试的实拍图。</p>

<p><img src="/OpenHW/assets/images/article_8/image_10.png" alt="image_10" /></p>

<p>通过对比，我们能够较为明显地看到处理效果。通常在低照度下拍摄的图像会呈现如下的效果。</p>

<p><img src="/OpenHW/assets/images/article_8/image_11.png" alt="image_11" /></p>

<p>如果为了图像效果，直接提高图像亮度，并提高对比度，则会产生较多噪声， 同时产生色彩偏移。图像会呈现如下的效果。</p>

<p><img src="/OpenHW/assets/images/article_8/image_12.png" alt="image_12" /></p>

<p>而经过 FPGA 中的图像处理系统处理后，图像的噪点被极大消去，色彩得到了校正，更加接近景物的原始色泽。图像呈现出如下的效果。</p>

<p><img src="/OpenHW/assets/images/article_8/image_13.png" alt="image_13" /></p>

<p>对上图的局部进行放大后，可以明显看到经过处理后的图像，在效果上有了明显的提升。下图是三处细节放大后的对比结果。</p>

<p><img src="/OpenHW/assets/images/article_8/image_14.png" alt="image_14" /></p>

<p> </p>

<p><strong>第四部分 总结</strong></p>

<p> </p>

<p>4.1 可扩展之处</p>

<p>（1）通过将更多的处理流程硬件化，减少在 AXI 总线上来回数据传输的次数，我们将进一步减少系统处理的平均用时，最后实现视频流的实时处理。之后，我们将为该系统加装摄像头模块，使得实时视频流经过系统处理后，以低时延输出。</p>

<p>（2）通过优化色调映射模块，我们计划在全局色调映射前加入局部色调映射，进一步提升在低照度下图像色彩的质量。</p>

<p>（3）通过调用 PYNQ-Z2 提供的 OpenCV 图像处理库，我们计划在图像处理流中增加人脸识别模块，对人脸识别激活的图块进行细致的配准及融合处理， 使得我们的图像处理系统在面对人脸时具有更好的效果。</p>
:ET